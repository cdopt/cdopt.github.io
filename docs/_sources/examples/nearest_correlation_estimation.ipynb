{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93795c68",
   "metadata": {},
   "source": [
    "# Low-Rank Nearest Correlation Estimation\n",
    "\n",
    "## Problem Description\n",
    "Given a symmetrix matrix $G \\in \\mathbb{R}^{n\\times n}$ and a nonnegative symmetric weigh matrix $H \\in \\mathbb{R}^{n\\times n}$, the low-rank nearest correlation estimation (NCM) problem aims to find a correlation matrix $W \\in \\mathbb{R}^{n\\times n}$ that minimizes the weighted distance between $W$ and $G$,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\min_{W \\in \\mathbb{R}^{n\\times n}}\\quad &\\frac{1}{2} || H\\circ( W - G ) ||_F^2  \\\\\n",
    "    \\text{s. t.} \\quad &W_{ii} = 1,~ i = 1,2,...,n, ~ \\mathrm{rank}(W) \\leq p. \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "We consider the low-rand descomposition of $W = X^\\top X$ with $X = [x_1,..., x_n]^\\top \\in \\mathbb{R}^{n\\times p}$. Then the NCM problem becomes \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\min_{X \\in \\mathbb{R}^{n\\times p}}\\quad &\\frac{1}{2} || H\\circ( X^\\top X - G ) ||_F^2  \\\\\n",
    "    \\text{s. t.} \\quad & ||x_i||_2^2 = 1, ~i = 1,...,n. \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Clearly, this problem is a smooth optimization problem on the Oblique manifold, and we show how to solve these problems with `cdopt` package."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc7d7d3",
   "metadata": {},
   "source": [
    "## Importing modules\n",
    "We first import all the necessary modules for this optimization problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "666297ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error importing backbone_jax Possibly JAX is not installed.\n",
      "No JAX package installed\n"
     ]
    }
   ],
   "source": [
    "import cdopt \n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import torch\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4afd96d",
   "metadata": {},
   "source": [
    "## Generating datas\n",
    "We generate necessary data and load the datas to GPU device. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecd0b362",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "p = 40\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dtype = torch.float64\n",
    "\n",
    "\n",
    "Y = torch.randn(n,p, device= device, dtype= dtype) \n",
    "Y = Y / torch.sqrt(torch.sum(Y ** 2, 1, keepdim= True))\n",
    "\n",
    "G = Y @ Y.T + 0.5 * torch.randn(n,n, device= device, dtype= dtype)\n",
    "H = (torch.rand(n,n, device= device, dtype= dtype ) + 1)/2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b94453b",
   "metadata": {},
   "source": [
    "## Set functions and problems\n",
    "\n",
    "Then we set the objective function and the Oblique manifold.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "474fe6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj_fun(X):\n",
    "    return 0.5 * torch.sum(  (H * (X@ X.T - G)) ** 2)\n",
    "\n",
    "M = cdopt.manifold_torch.oblique_torch((n,p), device=device, dtype= dtype)   # The Oblique manifold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5bffa6",
   "metadata": {},
   "source": [
    "## Describe the optimization problem \n",
    "\n",
    "The optimization problem can be described by the manifold and the expression of the objective function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ea0aee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_test = cdopt.core.Problem(M, obj_fun, beta = 5)  # describe the optimization problem and set the penalty parameter \\beta.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe8531a",
   "metadata": {},
   "source": [
    "## Apply optimization solvers\n",
    "\n",
    "After describe the optimization problem, we can directly function value, gradient and Hessian-vector product from the `cdopt.core.Problem` class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d39789d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solver   fval         iter   f_eval   stationarity   feaibility     CPU time\n",
      "& L-BFGS & 6.99e+04  & 82  & 90    & 3.44e-05     & 9.30e-07     & 0.86 \\\\\n"
     ]
    }
   ],
   "source": [
    "# the vectorized function value, gradient and Hessian-vector product of the constraint dissolving function. Their inputs are numpy 1D array, and their outputs are float or numpy 1D array.\n",
    "cdf_fun_np = problem_test.cdf_fun_vec_np   \n",
    "cdf_grad_np = problem_test.cdf_grad_vec_np \n",
    "cdf_hvp_np = problem_test.cdf_hvp_vec_np\n",
    "\n",
    "\n",
    "## Apply limit memory BFGS solver from scipy.minimize \n",
    "from scipy.optimize import fmin_bfgs, fmin_cg, fmin_l_bfgs_b, fmin_ncg\n",
    "Xinit = M.tensor2array(M.Init_point())  # set initial point\n",
    "\n",
    "t_start = time.time()\n",
    "out_msg = sp.optimize.minimize(cdf_fun_np, Xinit.flatten(),method='L-BFGS-B',jac = cdf_grad_np, options={'disp': None, 'maxcor': 10, 'ftol': 0, 'gtol': 1e-06, 'eps': 0e-08,})\n",
    "t_end = time.time() - t_start\n",
    "\n",
    "# Statistics\n",
    "feas = M.Feas_eval(M.v2m(M.array2tensor(out_msg.x)))   # Feasibility\n",
    "stationarity = np.linalg.norm(out_msg['jac'],2)   # stationarity\n",
    "\n",
    "result_lbfgs = [out_msg['fun'], out_msg['nit'], out_msg['nfev'],stationarity,feas, t_end]\n",
    "\n",
    "# print results\n",
    "print('Solver   fval         iter   f_eval   stationarity   feaibility     CPU time')\n",
    "print('& L-BFGS & {:.2e}  & {:}  & {:}    & {:.2e}     & {:.2e}     & {:.2f} \\\\\\\\'.format(*result_lbfgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4002ebf2",
   "metadata": {},
   "source": [
    "## Reference\n",
    "1.  Gao Y, Sun D F. A majorized penalty approach for calibrating rank constrained correlation matrix problems[J]. Preprint available at http://www.math.nus.edu.sg/~matsundf/MajorPen_May5.pdf, 2010, 4(9): 17."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2976304",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "07d5d4ebd289d7e3a8d5104fbc288ece76787e92d17b572773bddf91a0286b7c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('cdopt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
