{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93795c68",
   "metadata": {},
   "source": [
    "# Dictionary Learning Accelerated by JIT\n",
    "\n",
    "In this part, we use this simple example to illustrate that the optimization in CDOpt can be accelerated by the JIT compilation from JAX package. \n",
    "\n",
    "## Problem Description\n",
    "Given data $\\{y_i\\}_{i = 1,...,m}$ generated as $y_i = Q z_i$, where $Q$ is a fixed unknown orthogonal matrix and each $x_i$ folllows iid Bernoulli-Gaussian distributation with parameter $\\theta \\in (0,1)$. The goal is to recover $Z$ and $Q$ from the given data $Y = [y_1, ..., y_m]^\\top \\in \\mathrm{R}^{m\\times n}$. \n",
    "\n",
    "\n",
    "Based on the $\\ell_4$-norm maximization model proposed in [1,2], we can consider the following optimization problem,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\min_{X = [x_1,...x_n] \\in \\mathbb{R}^{n\\times n}} \\quad & f(X) := - \\sum_{1\\leq i\\leq m, 1\\leq j\\leq n} (y_i^\\top x_j)^4\\\\\n",
    "    \\text{s. t.} \\quad & X^TX = I_n. \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "This problem is nonconvex due to the nonconvex constraints. The constraints define the Stiefel manifold, hence this problem can be regarded as the smooth optimization problem over the Stiefel manifold. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc7d7d3",
   "metadata": {},
   "source": [
    "## Importing modules\n",
    "We first import all the necessary modules for this optimization problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "666297ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cdopt \n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.stats import norm\n",
    "from scipy.sparse import csr_matrix\n",
    "import time\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as random\n",
    "from jax.config import config\n",
    "config.update(\"jax_enable_x64\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4afd96d",
   "metadata": {},
   "source": [
    "## Generating datas\n",
    "We then specify torch device, and generate data\n",
    "\n",
    "We set the torch device as the GPU for this problem as default setting. If no cuda device available, we switch the device as the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecd0b362",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "n = 10        # dimension of the problem\n",
    "m = 10*n**2   # sample complexity\n",
    "theta = 0.3   # sparsity level\n",
    "\n",
    "Y = jnp.asarray(norm.ppf(np.random.rand(m,n)) * (norm.ppf(np.random.rand(m,n)) <= theta))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b94453b",
   "metadata": {},
   "source": [
    "## Set functions and problems\n",
    "\n",
    "Then we set the objective function and the Stiefel manifold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "474fe6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj_fun(X):\n",
    "    return - jnp.sum( (Y @ X) **4 )\n",
    "\n",
    "M = cdopt.manifold_jax.stiefel_jax((n,n))   # The Stiefel manifold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5bffa6",
   "metadata": {},
   "source": [
    "## Describe the optimization problem \n",
    "\n",
    "The optimization problem can be described only by the manifold and the objective function. All the other components are automatically computed by the automatic differentiation algorithms provided in `torch.autograd`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ea0aee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_test = cdopt.core.problem(M, obj_fun, beta = 500, enable_jit= True)  # describe the optimization problem and set the penalty parameter \\beta.\n",
    "problem_nojit = cdopt.core.problem(M, obj_fun, beta = 500, enable_jit= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e13861",
   "metadata": {},
   "source": [
    "We first compare the computation time of the gradient. It can be observed that JIT greatly accelerates the computation of the gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c91acad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = M.Init_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e9074b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114 µs ± 37.9 µs per loop (mean ± std. dev. of 3 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 100 -r 3 problem_test.cdf_grad(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd986245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265 µs ± 67.1 µs per loop (mean ± std. dev. of 3 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 100 -r 3 problem_nojit.cdf_grad(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe8531a",
   "metadata": {},
   "source": [
    "## Apply optimization solvers\n",
    "\n",
    "After describe the optimization problem, we can directly function value, gradient and Hessian-vector product from the `cdopt.core.Problem` class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d39789d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the vectorized function value, gradient and Hessian-vector product of the constraint dissolving function. Their inputs are numpy 1D array, and their outputs are float or numpy 1D array.\n",
    "cdf_fun_np = problem_test.cdf_fun_vec_np   \n",
    "cdf_grad_np = problem_test.cdf_grad_vec_np \n",
    "cdf_hvp_np = problem_test.cdf_hvp_vec_np\n",
    "\n",
    "\n",
    "## Apply limit memory BFGS solver from scipy.minimize \n",
    "from scipy.optimize import fmin_bfgs, fmin_cg, fmin_l_bfgs_b, fmin_ncg\n",
    "Xinit = problem_test.Xinit_vec_np  # set initial point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb2726e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solver   fval         iter   f_eval   stationarity   feaibility     CPU time\n",
      "& L-BFGS & -1.88e+04  & 63  & 70    & 2.61e-04     & 1.67e-08     & 0.05 \\\\\n"
     ]
    }
   ],
   "source": [
    "# optimize by L-BFGS method\n",
    "t_start = time.time()\n",
    "out_msg = sp.optimize.minimize(cdf_fun_np, Xinit,method='L-BFGS-B',jac = cdf_grad_np, options={'disp': None, 'maxcor': 10, 'ftol': 0, 'gtol': 1e-06, 'eps': 0e-08,})\n",
    "t_end = time.time() - t_start\n",
    "\n",
    "# Statistics\n",
    "feas = M.Feas_eval(M.v2m(M.array2tensor(out_msg.x)))   # Feasibility\n",
    "stationarity = np.linalg.norm(out_msg['jac'],2)   # stationarity\n",
    "\n",
    "result_lbfgs = [out_msg['fun'], out_msg['nit'], out_msg['nfev'],stationarity,feas, t_end]\n",
    "\n",
    "# print results\n",
    "print('Solver   fval         iter   f_eval   stationarity   feaibility     CPU time')\n",
    "print('& L-BFGS & {:.2e}  & {:}  & {:}    & {:.2e}     & {:.2e}     & {:.2f} \\\\\\\\'.format(*result_lbfgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3656d6ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4002ebf2",
   "metadata": {},
   "source": [
    "## Reference\n",
    "1.  Zhai Y, Yang Z, Liao Z, et al. Complete Dictionary Learning via L4-Norm Maximization over the Orthogonal Group[J]. J. Mach. Learn. Res., 2020, 21(165): 1-68.\n",
    "2.  Hu X, Liu X. An efficient orthonormalization-free approach for sparse dictionary learning and dual principal component pursuit[J]. Sensors, 2020, 20(11): 3041."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2976304",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 ('comp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "0d39dc981d7e245397dec99296e1c016cf2ce771713a096e96e8cdd420e6d603"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
