{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "G9rOr8ue2_FG",
      "metadata": {
        "id": "G9rOr8ue2_FG"
      },
      "source": [
        "# Training LeNet with Constrained Convolution Kernels by JAX and FLAX\n",
        "The following code illustrates how to train LeNet with orthogonally constrained convolution kernels by JAX and FLAX. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7056890b",
      "metadata": {},
      "source": [
        "## Set-up\n",
        "We first install essential packages. If you run this example on Google colab, you need to install CDOpt and FLAX everytime you run this notebook. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "eb97b12b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb97b12b",
        "outputId": "8698d938-6fe2-45dc-d2d3-a83b1e2c2667"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: cdopt in /usr/local/lib/python3.7/dist-packages (0.3.0)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.7/dist-packages (from cdopt) (1.4)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from cdopt) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from cdopt) (1.4.1)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.7/dist-packages (from autograd->cdopt) (0.16.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install cdopt --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "zWizlHJ2PC3I",
      "metadata": {
        "id": "zWizlHJ2PC3I"
      },
      "outputs": [],
      "source": [
        "!pip install -q ml-collections git+https://github.com/google/flax"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d3529e7",
      "metadata": {},
      "source": [
        "## Import essential modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6MHCQSUxPDWR",
      "metadata": {
        "id": "6MHCQSUxPDWR"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp                # JAX NumPy\n",
        "\n",
        "from flax import linen as nn           # The Linen API\n",
        "from flax.training import train_state  # Useful dataclass to keep train state\n",
        "\n",
        "import numpy as np                     # Ordinary NumPy\n",
        "import optax                           # Optimizers\n",
        "import tensorflow_datasets as tfds     # TFDS for MNIST\n",
        "\n",
        "import cdopt\n",
        "from cdopt.manifold_jax import sphere_jax, stiefel_jax, euclidean_jax\n",
        "from cdopt.linen import Dense_cdopt, Conv_cdopt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12835e29",
      "metadata": {},
      "source": [
        "## Creat neural network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ef2a6f8e",
      "metadata": {
        "id": "ef2a6f8e"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "  \"\"\"A simple CNN model.\"\"\"\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    x, quad_penalty0 = Conv_cdopt(features=32, kernel_size=(3, 3), manifold_class = stiefel_jax)(x)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
        "    x = nn.Conv(features=64, kernel_size=(3, 3))(x)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
        "    x = x.reshape((x.shape[0], -1))  # flatten\n",
        "    x, quad_penalty1 = Dense_cdopt(features=256)(x)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.Dense(features=10)(x)\n",
        "    return x, quad_penalty0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4af85efc",
      "metadata": {},
      "source": [
        "## Define essential components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "4632d31f",
      "metadata": {
        "id": "4632d31f"
      },
      "outputs": [],
      "source": [
        "# Define the metric as cross entropy loss\n",
        "def cross_entropy_loss(*, logits, labels):\n",
        "  labels_onehot = jax.nn.one_hot(labels, num_classes=10)\n",
        "  return optax.softmax_cross_entropy(logits=logits, labels=labels_onehot).mean()\n",
        "\n",
        "def compute_metrics(*, logits, labels, feas = 0):\n",
        "  loss = cross_entropy_loss(logits=logits, labels=labels)\n",
        "  accuracy = jnp.mean(jnp.argmax(logits, -1) == labels)\n",
        "  metrics = {\n",
        "      'loss': loss,\n",
        "      'accuracy': accuracy,\n",
        "      'feas': feas\n",
        "  }\n",
        "  return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "36a94ce7",
      "metadata": {
        "id": "36a94ce7"
      },
      "outputs": [],
      "source": [
        "# Set training process\n",
        "def create_train_state(rng, learning_rate, momentum):\n",
        "  \"\"\"Creates initial `TrainState`.\"\"\"\n",
        "  cnn = CNN()\n",
        "  params = cnn.init(rng, jnp.ones([1, 28, 28, 1]))['params']\n",
        "  tx = optax.sgd(learning_rate, momentum)\n",
        "  return train_state.TrainState.create(\n",
        "      apply_fn=cnn.apply, params=params, tx=tx)\n",
        "\n",
        "@jax.jit\n",
        "def train_step(state, batch):\n",
        "  \"\"\"Train for a single step.\"\"\"\n",
        "  def loss_fn(params):\n",
        "    logits, quad_penalty = CNN().apply({'params': params}, batch['image'])\n",
        "    loss = cross_entropy_loss(logits=logits, labels=batch['label']) + 0.05*quad_penalty\n",
        "    return loss, logits\n",
        "  grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
        "  (_, logits), grads = grad_fn(state.params)\n",
        "  state = state.apply_gradients(grads=grads)\n",
        "  metrics = compute_metrics(logits=logits, labels=batch['label'])\n",
        "  return state, metrics\n",
        "\n",
        "def train_epoch(state, train_ds, batch_size, epoch, rng):\n",
        "  \"\"\"Train for a single epoch.\"\"\"\n",
        "  train_ds_size = len(train_ds['image'])\n",
        "  steps_per_epoch = train_ds_size // batch_size\n",
        "\n",
        "  perms = jax.random.permutation(rng, train_ds_size)\n",
        "  perms = perms[:steps_per_epoch * batch_size]  # skip incomplete batch\n",
        "  perms = perms.reshape((steps_per_epoch, batch_size))\n",
        "  batch_metrics = []\n",
        "  for perm in perms:\n",
        "    batch = {k: v[perm, ...] for k, v in train_ds.items()}\n",
        "    state, metrics = train_step(state, batch)\n",
        "    batch_metrics.append(metrics)\n",
        "\n",
        "  # compute mean of metrics across each batch in epoch.\n",
        "  batch_metrics_np = jax.device_get(batch_metrics)\n",
        "  epoch_metrics_np = {\n",
        "      k: np.mean([metrics[k] for metrics in batch_metrics_np])\n",
        "      for k in batch_metrics_np[0]}\n",
        "\n",
        "  print('train epoch: %d, loss: %.4f, accuracy: %.2f' % (\n",
        "      epoch, epoch_metrics_np['loss'], epoch_metrics_np['accuracy'] * 100))\n",
        "\n",
        "  return state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "4f426abf",
      "metadata": {
        "id": "4f426abf"
      },
      "outputs": [],
      "source": [
        "# Set testing process\n",
        "@jax.jit\n",
        "def eval_step(params, batch):\n",
        "  logits, quad_penalty = CNN().apply({'params': params}, batch['image'])\n",
        "  return compute_metrics(logits=logits, labels=batch['label'], feas = quad_penalty)\n",
        "\n",
        "def eval_model(params, test_ds):\n",
        "  metrics = eval_step(params, test_ds)\n",
        "  metrics = jax.device_get(metrics)\n",
        "  summary = jax.tree_map(lambda x: x.item(), metrics)\n",
        "  return summary['loss'], summary['accuracy'], summary['feas']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "a5d74a68",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5d74a68",
        "outputId": "c224f7ce-7316-44cb-c382-1dff18237774"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_datasets/core/dataset_builder.py:598: get_single_element (from tensorflow.python.data.experimental.ops.get_single_element) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.get_single_element()`.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_datasets/core/dataset_builder.py:598: get_single_element (from tensorflow.python.data.experimental.ops.get_single_element) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.get_single_element()`.\n"
          ]
        }
      ],
      "source": [
        "# Import dataset\n",
        "def get_datasets():\n",
        "  \"\"\"Load MNIST train and test datasets into memory.\"\"\"\n",
        "  ds_builder = tfds.builder('mnist')\n",
        "  ds_builder.download_and_prepare()\n",
        "  train_ds = tfds.as_numpy(ds_builder.as_dataset(split='train', batch_size=-1))\n",
        "  test_ds = tfds.as_numpy(ds_builder.as_dataset(split='test', batch_size=-1))\n",
        "  train_ds['image'] = jnp.float32(train_ds['image']) / 255.\n",
        "  test_ds['image'] = jnp.float32(test_ds['image']) / 255.\n",
        "  return train_ds, test_ds\n",
        "\n",
        "\n",
        "train_ds, test_ds = get_datasets()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec58e181",
      "metadata": {},
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "9a1f4a4e",
      "metadata": {
        "id": "9a1f4a4e"
      },
      "outputs": [],
      "source": [
        "rng = jax.random.PRNGKey(0)\n",
        "rng, init_rng = jax.random.split(rng)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "195be7f6",
      "metadata": {
        "id": "195be7f6"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.05\n",
        "momentum = 0.9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "b7f60731",
      "metadata": {
        "id": "b7f60731"
      },
      "outputs": [],
      "source": [
        "state = create_train_state(init_rng, learning_rate, momentum)\n",
        "del init_rng  # Must not be used anymore."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "c55178d3",
      "metadata": {
        "id": "c55178d3"
      },
      "outputs": [],
      "source": [
        "num_epochs = 10\n",
        "batch_size = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "2128bb78",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2128bb78",
        "outputId": "3710ef16-c7a8-4395-b6de-fa6d856f6ed9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train epoch: 1, loss: 0.2912, accuracy: 90.97\n",
            " test epoch: 1, loss: 0.09, accuracy: 97.14, feas: 4.37e-05\n",
            "train epoch: 2, loss: 0.0841, accuracy: 97.43\n",
            " test epoch: 2, loss: 0.07, accuracy: 97.72, feas: 5.71e-05\n",
            "train epoch: 3, loss: 0.0633, accuracy: 98.10\n",
            " test epoch: 3, loss: 0.06, accuracy: 98.26, feas: 3.86e-03\n",
            "train epoch: 4, loss: 0.0497, accuracy: 98.44\n",
            " test epoch: 4, loss: 0.04, accuracy: 98.71, feas: 2.13e-06\n",
            "train epoch: 5, loss: 0.0415, accuracy: 98.75\n",
            " test epoch: 5, loss: 0.04, accuracy: 98.89, feas: 1.25e-04\n",
            "train epoch: 6, loss: 0.0362, accuracy: 98.91\n",
            " test epoch: 6, loss: 0.04, accuracy: 98.69, feas: 1.20e-04\n",
            "train epoch: 7, loss: 0.0308, accuracy: 99.06\n",
            " test epoch: 7, loss: 0.04, accuracy: 98.64, feas: 2.92e-06\n",
            "train epoch: 8, loss: 0.0280, accuracy: 99.12\n",
            " test epoch: 8, loss: 0.04, accuracy: 98.89, feas: 1.20e-04\n",
            "train epoch: 9, loss: 0.0241, accuracy: 99.22\n",
            " test epoch: 9, loss: 0.04, accuracy: 98.77, feas: 3.83e-05\n",
            "train epoch: 10, loss: 0.0209, accuracy: 99.31\n",
            " test epoch: 10, loss: 0.04, accuracy: 98.87, feas: 4.69e-04\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(1, num_epochs + 1):\n",
        "  # Use a separate PRNG key to permute image data during shuffling\n",
        "  rng, input_rng = jax.random.split(rng)\n",
        "  # Run an optimization step over a training batch\n",
        "  state = train_epoch(state, train_ds, batch_size, epoch, input_rng)\n",
        "  # Evaluate on the test set after each training epoch \n",
        "  test_loss, test_accuracy, feas = eval_model(state.params, test_ds)\n",
        "  print(' test epoch: %d, loss: %.2f, accuracy: %.2f, feas: %.2e' % (\n",
        "      epoch, test_loss, test_accuracy * 100, feas))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "348bfe5b",
      "metadata": {},
      "source": [
        "## Reference\n",
        "1. https://github.com/google/flax/tree/main/examples/mnist\n",
        "2. Hu X, Xiao N, Liu X, et al. A Constraint Dissolving Approach for Nonsmooth Optimization over the Stiefel Manifold[J]. arXiv preprint arXiv:2205.10500, 2022."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "test_flax.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "2f6c3b01c8b2ae1ebbf9c4120052c3bea6c439c8bfde40482604046164e024f3"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
