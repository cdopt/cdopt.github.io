
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Quickstart &#8212; Constraint Dissolving Approaches for Riemannian Optimization</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=62ba249389abaaa9ffc34bf36a076bdc1d65ee18" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.14.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Define your own manifold" href="define_manifolds.html" />
    <link rel="prev" title="Tutorials" href="../tutorial.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Constraint Dissolving Approaches for Riemannian Optimization</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Welcome to CDOpt
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../overview.html">
   Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../installation.html">
   Installation
  </a>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../tutorial.html">
   Tutorials
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Quickstart
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="define_manifolds.html">
     Define your own manifold
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="build_networks.html">
     Training neural networks with constrained weights
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../examples.html">
   Examples
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../examples/example_scipy.html">
     Optimization via SciPy
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
    <label for="toctree-checkbox-3">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../examples/dictionary_learning.html">
       Dictionary Learning
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../examples/nonlinear_eigenvalue.html">
       Discretized 1D Kohn-Sham Equation
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../examples/nearest_correlation_estimation.html">
       Low-Rank Nearest Correlation Estimation
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../examples/bose_einstein_condensates.html">
       Bose–Einstein Condensates
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../examples/symplectic_eigenvalue.html">
       Symplectic Eigenvalue Problem
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../examples/example_torch.html">
     Training Neural Networks with Manifold Constraints via PyTorch
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
    <label for="toctree-checkbox-4">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../examples/LeNet_orth.html">
       Traning Neural Networks with Constrained Weights
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../examples/rnn_single_layer.html">
       Training Single-Layer RNN with Constrained Weights
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../examples/rnn_multi_layer.html">
       Training Multi-Layer RNN with Constrained Weights
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../examples/rnn_lstm.html">
       Training LSTM with Constrained Weights
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../api_reference.html">
   API Reference
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../apis/cdopt_core.html">
     cdopt.core
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../apis/cdopt_manifold.html">
     cdopt.manifold
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../apis/cdopt_manifold_np.html">
     cdopt.manifold_np
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
    <label for="toctree-checkbox-6">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../apis/manifold_np/basic_manifold_np.html">
       basic_manifold_np
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../apis/manifold_np/euclidean_np.html">
       euclidean_np
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../apis/manifold_np/sphere_np.html">
       sphere_np
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../apis/manifold_np/oblique_np.html">
       oblique_np
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../apis/manifold_np/stiefel_np.html">
       stiefel_np
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../apis/manifold_np/generalized_stiefel_np.html">
       generalized_stiefel_np
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../apis/manifold_np/hyperbolic_np.html">
       hyperbolic_np
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../apis/manifold_np/symp_stiefel_np.html">
       symp_stiefel_np
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../apis/cdopt_manifold_torch.html">
     cdopt.manifold_torch
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
    <label for="toctree-checkbox-7">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../apis/manifold_torch/basic_manifold_torch.html">
       basic_manifold_torch
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../apis/manifold_torch/euclidean_torch.html">
       euclidean_torch
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../apis/manifold_torch/sphere_torch.html">
       sphere_torch
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../apis/manifold_torch/oblique_torch.html">
       oblique_torch
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../apis/manifold_torch/stiefel_torch.html">
       stiefel_torch
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../apis/manifold_torch/generalized_stiefel_torch.html">
       generalized_stiefel_torch
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../apis/manifold_torch/hyperbolic_torch.html">
       hyperbolic_torch
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../apis/manifold_torch/symp_stiefel_torch.html">
       symp_stiefel_torch
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/xnchxy/constraint_dissolving_lib"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/xnchxy/constraint_dissolving_lib/issues/new?title=Issue%20on%20page%20%2Fmd_files/tutorials/quick_start.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/md_files/tutorials/quick_start.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-simple-example">
   A simple example
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#manifolds">
   Manifolds
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#solvers">
   Solvers
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#automatic-differentiation-backbones">
   Automatic differentiation backbones
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cuda-support">
   CUDA support
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Quickstart</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-simple-example">
   A simple example
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#manifolds">
   Manifolds
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#solvers">
   Solvers
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#automatic-differentiation-backbones">
   Automatic differentiation backbones
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cuda-support">
   CUDA support
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="quickstart">
<h1>Quickstart<a class="headerlink" href="#quickstart" title="Permalink to this headline">#</a></h1>
<div class="section" id="a-simple-example">
<h2>A simple example<a class="headerlink" href="#a-simple-example" title="Permalink to this headline">#</a></h2>
<p>We begin with a simple optimization problem with orthogonality constraints,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
		\min_{X \in \mathbb{R}^{m\times s}}\quad &amp;f(X) = -\frac{1}{2}\mathrm{tr}(X^\top HX)\\
		\text{s.t.} \quad &amp; X^\top X = I_s,
	\end{aligned}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(H \in \mathbb{R}^{m\times m}\)</span> is a symmetric matrix, and the gradient of <span class="math notranslate nohighlight">\(f\)</span> can be expressed as</p>
<div class="math notranslate nohighlight">
\[
\nabla f(X) = -HX.
\]</div>
<p>The constraints on the matrix <span class="math notranslate nohighlight">\(X\)</span> require that <span class="math notranslate nohighlight">\(X\)</span> is an orthogonal matrix, i.e., <span class="math notranslate nohighlight">\(X\)</span> lies on the Stiefel manifold,</p>
<div class="math notranslate nohighlight">
\[
	\mathcal{S}_{m,s} = \{X \in \mathbb{R}^{m\times s}: X^\top X = I_s  \}. 
\]</div>
<p>The following is a minimal working example of how to solve the above problem using <code class="docutils literal notranslate"><span class="pre">cdopt</span></code> for a random symmetric matrix. As indicated in the introduction above, we follow four simple steps: we instantiate the manifold, create the cost function (using Autograd in this case), define a problem instance which we pass the manifold and the cost function, and run the minimization problem using one of the existing unconstrained optimization solvers.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import basic functions</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy</span> <span class="k">as</span> <span class="nn">sp</span>
<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">fmin_bfgs</span><span class="p">,</span> <span class="n">fmin_cg</span><span class="p">,</span> <span class="n">fmin_l_bfgs_b</span><span class="p">,</span> <span class="n">fmin_ncg</span>
<span class="kn">import</span> <span class="nn">torch</span> 
<span class="kn">import</span> <span class="nn">cdopt</span>
<span class="kn">from</span> <span class="nn">cdopt.manifold_torch</span> <span class="kn">import</span> <span class="n">stiefel_torch</span>
<span class="kn">from</span> <span class="nn">cdopt.core.problem</span> <span class="kn">import</span> <span class="n">Problem</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="c1"># Set parameters</span>
<span class="n">m</span> <span class="o">=</span> <span class="mi">200</span>  <span class="c1"># column size</span>
<span class="n">s</span> <span class="o">=</span> <span class="mi">8</span>    <span class="c1"># row size</span>
<span class="n">beta</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># penalty parameter</span>
<span class="n">local_device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>  <span class="c1"># the device to perform the computation</span>
<span class="n">local_dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float64</span>  <span class="c1"># the data type of the pytorch tensor</span>

<span class="c1"># Define object function</span>
<span class="n">H</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="n">m</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span> <span class="o">=</span><span class="n">local_device</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">local_dtype</span><span class="p">)</span>
<span class="n">H</span> <span class="o">=</span> <span class="n">H</span><span class="o">+</span><span class="n">H</span><span class="o">.</span><span class="n">T</span> 

<span class="k">def</span> <span class="nf">obj_fun</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="k">return</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span> <span class="n">X</span> <span class="o">*</span> <span class="p">(</span><span class="n">H</span><span class="nd">@X</span><span class="p">))</span> 


<span class="c1"># Set optimization problems and retrieve constraint dissolving functions.</span>
<span class="n">M</span> <span class="o">=</span> <span class="n">stiefel_torch</span><span class="p">((</span><span class="n">m</span><span class="p">,</span><span class="n">s</span><span class="p">),</span> <span class="n">device</span> <span class="o">=</span><span class="n">local_device</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">local_dtype</span> <span class="p">)</span>
<span class="n">problem_test</span> <span class="o">=</span> <span class="n">Problem</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">obj_fun</span><span class="p">,</span> <span class="n">beta</span> <span class="o">=</span> <span class="n">beta</span><span class="p">)</span>

<span class="n">cdf_fun_np</span> <span class="o">=</span> <span class="n">problem_test</span><span class="o">.</span><span class="n">cdf_fun_vec_np</span>
<span class="n">cdf_grad_np</span> <span class="o">=</span> <span class="n">problem_test</span><span class="o">.</span><span class="n">cdf_grad_vec_np</span>
<span class="n">cdf_hvp_np</span> <span class="o">=</span> <span class="n">problem_test</span><span class="o">.</span><span class="n">cdf_hvp_vec_np</span>

<span class="c1"># Implement L-BFGS solver from scipy.optimize</span>
<span class="n">Xinit</span> <span class="o">=</span> <span class="n">M</span><span class="o">.</span><span class="n">tensor2array</span><span class="p">(</span><span class="n">M</span><span class="o">.</span><span class="n">Init_point</span><span class="p">())</span>
<span class="n">t_start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">out_msg</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">optimize</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">cdf_fun_np</span><span class="p">,</span> <span class="n">Xinit</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;L-BFGS-B&#39;</span><span class="p">,</span><span class="n">jac</span> <span class="o">=</span> <span class="n">cdf_grad_np</span><span class="p">)</span>
<span class="n">t_end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t_start</span>

<span class="c1"># Statistics</span>
<span class="n">feas</span> <span class="o">=</span> <span class="n">M</span><span class="o">.</span><span class="n">Feas_eval</span><span class="p">(</span><span class="n">M</span><span class="o">.</span><span class="n">v2m</span><span class="p">(</span><span class="n">M</span><span class="o">.</span><span class="n">array2tensor</span><span class="p">(</span><span class="n">out_msg</span><span class="o">.</span><span class="n">x</span><span class="p">)))</span>   <span class="c1"># Feasibility</span>
<span class="n">stationarity</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">out_msg</span><span class="p">[</span><span class="s1">&#39;jac&#39;</span><span class="p">],</span><span class="mi">2</span><span class="p">)</span>   <span class="c1"># stationarity</span>
<span class="n">result_lbfgs</span> <span class="o">=</span> <span class="p">[</span><span class="n">out_msg</span><span class="p">[</span><span class="s1">&#39;fun&#39;</span><span class="p">],</span> <span class="n">out_msg</span><span class="p">[</span><span class="s1">&#39;nit&#39;</span><span class="p">],</span> <span class="n">out_msg</span><span class="p">[</span><span class="s1">&#39;nfev&#39;</span><span class="p">],</span><span class="n">stationarity</span><span class="p">,</span><span class="n">feas</span><span class="p">,</span> <span class="n">t_end</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&amp; L-BFGS &amp; </span><span class="si">{:.2e}</span><span class="s1"> &amp; </span><span class="si">{:}</span><span class="s1"> &amp; </span><span class="si">{:}</span><span class="s1"> &amp; </span><span class="si">{:.2e}</span><span class="s1"> &amp; </span><span class="si">{:.2e}</span><span class="s1"> &amp; </span><span class="si">{:.2f}</span><span class="s1"> </span><span class="se">\\\\</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">result_lbfgs</span><span class="p">))</span>
</pre></div>
</div>
<p>Now let us take a deeper look at the code step by step. First, <code class="docutils literal notranslate"><span class="pre">cdopt</span></code> imports necessary packages and set the parameters.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import basic functions</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy</span> <span class="k">as</span> <span class="nn">sp</span>
<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">fmin_bfgs</span><span class="p">,</span> <span class="n">fmin_cg</span><span class="p">,</span> <span class="n">fmin_l_bfgs_b</span><span class="p">,</span> <span class="n">fmin_ncg</span>
<span class="kn">import</span> <span class="nn">torch</span> 
<span class="kn">import</span> <span class="nn">cdopt</span>
<span class="kn">from</span> <span class="nn">cdopt.manifold_torch</span> <span class="kn">import</span> <span class="n">stiefel_torch</span>
<span class="kn">from</span> <span class="nn">cdopt.core.problem</span> <span class="kn">import</span> <span class="n">Problem</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="c1"># Set parameters</span>
<span class="n">m</span> <span class="o">=</span> <span class="mi">200</span>  <span class="c1"># column size</span>
<span class="n">s</span> <span class="o">=</span> <span class="mi">8</span>    <span class="c1"># row size</span>
<span class="n">beta</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># penalty parameter</span>
<span class="n">local_device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>  <span class="c1"># the device to perform the computation</span>
<span class="n">local_dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float64</span>  <span class="c1"># the data type of the pytorch tensor</span>
</pre></div>
</div>
<p>Then we describe the objective function, where the variables are PyTorch tensors. The cost function should be a</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define object function</span>
<span class="n">H</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="n">m</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span> <span class="o">=</span><span class="n">local_device</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">local_dtype</span><span class="p">)</span>
<span class="n">H</span> <span class="o">=</span> <span class="n">H</span><span class="o">+</span><span class="n">H</span><span class="o">.</span><span class="n">T</span> 

<span class="k">def</span> <span class="nf">obj_fun</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="k">return</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span> <span class="n">X</span> <span class="o">*</span> <span class="p">(</span><span class="n">H</span><span class="nd">@X</span><span class="p">))</span>  
</pre></div>
</div>
<p>Then we call <code class="docutils literal notranslate"><span class="pre">stiefel_torch</span></code> to generate a structure that describes the Stiefel manifold <span class="math notranslate nohighlight">\(\mathcal{S}_{n,p}\)</span>. This manifold corresponds to the constraint appearing in our optimization problem. For other constraints, take a look at the <a class="reference external" href="#manifolds">various supported manifolds</a> for details. The second instruction creates a structure named <code class="docutils literal notranslate"><span class="pre">problem_test</span></code>. Here the gradients and hessians of the objective function are not necessary, as they can be computed by the automatic differentiation (AD) packages.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set optimization problems and retrieve constraint dissolving functions.</span>
<span class="n">M</span> <span class="o">=</span> <span class="n">stiefel_torch</span><span class="p">((</span><span class="n">m</span><span class="p">,</span><span class="n">s</span><span class="p">),</span> <span class="n">device</span> <span class="o">=</span><span class="n">local_device</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">local_dtype</span> <span class="p">)</span>
<span class="n">problem_test</span> <span class="o">=</span> <span class="n">Problem</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">obj_fun</span><span class="p">,</span> <span class="n">beta</span> <span class="o">=</span> <span class="n">beta</span><span class="p">)</span>
</pre></div>
</div>
<p>After describe the optimization problem, we can directly retrieve the function value, gradients, Hessian of the corresponding constraint dissolving function.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get the objective function, gradient, hessian-vector product </span>
<span class="c1"># of the corresponding constraint dissolving function</span>
<span class="n">cdf_fun_np</span> <span class="o">=</span> <span class="n">problem_test</span><span class="o">.</span><span class="n">cdf_fun_vec_np</span>   
<span class="n">cdf_grad_np</span> <span class="o">=</span> <span class="n">problem_test</span><span class="o">.</span><span class="n">cdf_grad_vec_np</span>
<span class="n">cdf_hvp_np</span> <span class="o">=</span> <span class="n">problem_test</span><span class="o">.</span><span class="n">cdf_hvp_vec_np</span>
</pre></div>
</div>
<p>Finally, we call the unconstraint solver from <code class="docutils literal notranslate"><span class="pre">scipy.optimize</span></code> package to minimize the constraint dissolving function over <span class="math notranslate nohighlight">\(\mathbb{R}^{n\times p}\)</span>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Implement L-BFGS solver from scipy.optimize</span>
<span class="n">Xinit</span> <span class="o">=</span> <span class="n">M</span><span class="o">.</span><span class="n">tensor2array</span><span class="p">(</span><span class="n">M</span><span class="o">.</span><span class="n">Init_point</span><span class="p">())</span>
<span class="n">t_start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">out_msg</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">optimize</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">cdf_fun_np</span><span class="p">,</span> <span class="n">Xinit</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;L-BFGS-B&#39;</span><span class="p">,</span><span class="n">jac</span> <span class="o">=</span> <span class="n">cdf_grad_np</span><span class="p">)</span>
<span class="n">t_end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t_start</span>

<span class="c1"># Statistics</span>
<span class="n">feas</span> <span class="o">=</span> <span class="n">M</span><span class="o">.</span><span class="n">Feas_eval</span><span class="p">(</span><span class="n">M</span><span class="o">.</span><span class="n">v2m</span><span class="p">(</span><span class="n">M</span><span class="o">.</span><span class="n">array2tensor</span><span class="p">(</span><span class="n">out_msg</span><span class="o">.</span><span class="n">x</span><span class="p">)))</span>   <span class="c1"># Feasibility</span>
<span class="n">stationarity</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">out_msg</span><span class="p">[</span><span class="s1">&#39;jac&#39;</span><span class="p">],</span><span class="mi">2</span><span class="p">)</span>   <span class="c1"># stationarity</span>
<span class="n">result_lbfgs</span> <span class="o">=</span> <span class="p">[</span><span class="n">out_msg</span><span class="p">[</span><span class="s1">&#39;fun&#39;</span><span class="p">],</span> <span class="n">out_msg</span><span class="p">[</span><span class="s1">&#39;nit&#39;</span><span class="p">],</span> <span class="n">out_msg</span><span class="p">[</span><span class="s1">&#39;nfev&#39;</span><span class="p">],</span><span class="n">stationarity</span><span class="p">,</span><span class="n">feas</span><span class="p">,</span> <span class="n">t_end</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&amp; L-BFGS &amp; </span><span class="si">{:.2e}</span><span class="s1"> &amp; </span><span class="si">{:}</span><span class="s1"> &amp; </span><span class="si">{:}</span><span class="s1"> &amp; </span><span class="si">{:.2e}</span><span class="s1"> &amp; </span><span class="si">{:.2e}</span><span class="s1"> &amp; </span><span class="si">{:.2f}</span><span class="s1"> </span><span class="se">\\\\</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">result_lbfgs</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="section" id="manifolds">
<h2>Manifolds<a class="headerlink" href="#manifolds" title="Permalink to this headline">#</a></h2>
<p>For several well-known manifolds, we provide build-in expressions for <span class="math notranslate nohighlight">\(\mathcal{A}\)</span> in the following table. We strongly suggest you to use the provided structures to define the manifold if it is included in the following table.</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Expression of <span class="math notranslate nohighlight">\(c\)</span></p></th>
<th class="head"><p>Pre-defined structure from <code class="docutils literal notranslate"><span class="pre">autograd</span></code></p></th>
<th class="head"><p>Pre-defined structure from<code class="docutils literal notranslate"><span class="pre">PyTorch</span></code></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Euclidean space</p></td>
<td><p>No constraint</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">manifold_np.euclidean_np</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">manifold_torch.euclidean_torch</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>Sphere</p></td>
<td><p><span class="math notranslate nohighlight">\(\left\{ x \in \mathbb{R}^{n}: x^\top x = 1 \right\}\)</span></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">manifold_np.sphere_np</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">manifold_torch.sphere_torch</span></code></p></td>
</tr>
<tr class="row-even"><td><p>Oblique manifold</p></td>
<td><p><span class="math notranslate nohighlight">\(\left\{ X \in \mathbb{R}^{m\times s}: \mathrm{Diag} (X ^\top X) = I_s \right\}\)</span></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">manifold_np.obluqie_np</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">manifold_torch.obluqie_torch</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>Stiefel manifold</p></td>
<td><p><span class="math notranslate nohighlight">\(\left\{ X \in \mathbb{R}^{m\times s}: X ^\top X = I_s \right\}\)</span></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">manifold_np.stiefel_np</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">manifold_torch.stiefel_torch</span></code></p></td>
</tr>
<tr class="row-even"><td><p>Grassmann manifold</p></td>
<td><p><span class="math notranslate nohighlight">\(\left\{ \mathrm{range}(X): X \in \mathbb{R}^{m\times s}, X ^\top X = I_s \right\}\)</span></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">manifold_np.stiefel_np</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">manifold_torch.stiefel_torch</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>Generalized Stiefel manifold</p></td>
<td><p><span class="math notranslate nohighlight">\(\left\{ X \in \mathbb{R}^{m\times s}: X ^\top B X = I_s \right\}\)</span>, <span class="math notranslate nohighlight">\(B\)</span> is positive definite</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">manifold_np.generalized_stiefel_np</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">manifold_torch.generalized_stiefel_torch</span></code></p></td>
</tr>
<tr class="row-even"><td><p>Generalized Grassmann manifold</p></td>
<td><p><span class="math notranslate nohighlight">\(\left\{ \mathrm{range}(X): X \in \mathbb{R}^{m\times s}, X ^\top B X = I_s \right\}\)</span>, <span class="math notranslate nohighlight">\(B\)</span> is positive definite</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">manifold_np.generalized_stiefel_np</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">manifold_torch.generalized_stiefel_torch</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>Hyperbolic manifold</p></td>
<td><p><span class="math notranslate nohighlight">\(\left\{ X \in \mathbb{R}^{m\times s}: X ^\top B X = I_s \right\}\)</span>, <span class="math notranslate nohighlight">\(\lambda_{\min}(B)&lt; 0 &lt; \lambda_{\max}(B)\)</span></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">manifold_np.hyperbolic_np</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">manifold_torch.hyperbolic_torch</span></code></p></td>
</tr>
<tr class="row-even"><td><p>Symplectic Stiefel manifold</p></td>
<td><p><span class="math notranslate nohighlight">\(\left\{ X \in \mathbb{R}^{2m\times 2s}: X ^\top Q_m X = Q_s \right\}\)</span>, <span class="math notranslate nohighlight">\(Q_m := \left[ \begin{smallmatrix}	{\bf 0}_{m\times m} &amp; I_m\\			 -I_m &amp; {\bf 0}_{m\times m}			\end{smallmatrix}\right]\)</span></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">manifold_np.symp_stiefel_np</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">manifold_torch.symp_stiefel_torch</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>…</p></td>
<td><p>…</p></td>
<td><p>…</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="solvers">
<h2>Solvers<a class="headerlink" href="#solvers" title="Permalink to this headline">#</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">cdopt</span></code> package does not contain any solvers. However, the unconstrained minimization of the constraint dissolving functions can be solved by various of existing solvers. The solvers from <code class="docutils literal notranslate"><span class="pre">scipy.optimize</span></code>, <code class="docutils literal notranslate"><span class="pre">torch.optim</span></code> and <code class="docutils literal notranslate"><span class="pre">torch_optimizer</span></code> can be directly applied to minimize CDF over <span class="math notranslate nohighlight">\(\mathbb{R}^n\)</span>.</p>
</div>
<div class="section" id="automatic-differentiation-backbones">
<h2>Automatic differentiation backbones<a class="headerlink" href="#automatic-differentiation-backbones" title="Permalink to this headline">#</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">cdopt</span></code> relies on the automatic differentiation (AD) packages to compute the derivatives of the objective function and build the constraint dissolving mapping. In <code class="docutils literal notranslate"><span class="pre">cdopt</span></code>, we provide various of plug-in AD backbones in <code class="docutils literal notranslate"><span class="pre">cdopt.core</span></code> based on <code class="docutils literal notranslate"><span class="pre">autograd</span></code> and <code class="docutils literal notranslate"><span class="pre">torch.autograd</span></code> packages. Moreover, one can easily build his own AD backbones by other packages, including the <code class="docutils literal notranslate"><span class="pre">jax</span></code> and <code class="docutils literal notranslate"><span class="pre">tensorflow</span></code>.</p>
</div>
<div class="section" id="cuda-support">
<h2>CUDA support<a class="headerlink" href="#cuda-support" title="Permalink to this headline">#</a></h2>
<p>The CUDA support for<code class="docutils literal notranslate"><span class="pre">cdopt</span></code> relies on the employed backbones. Both the computation of constraint dissolving mappings and the unconstrained minimization of CDF can be accelerated by the CUDA support of the selected backbones.</p>
<p>For example, by setting the <code class="docutils literal notranslate"><span class="pre">local_device</span> <span class="pre">=</span> <span class="pre">torch.device('cuda')</span></code> in the following code blocks, all the computations for CDF are accelerated by CUDA.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import basic functions</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy</span> <span class="k">as</span> <span class="nn">sp</span>
<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">fmin_bfgs</span><span class="p">,</span> <span class="n">fmin_cg</span><span class="p">,</span> <span class="n">fmin_l_bfgs_b</span><span class="p">,</span> <span class="n">fmin_ncg</span>
<span class="kn">import</span> <span class="nn">torch</span> 
<span class="kn">import</span> <span class="nn">cdopt</span>
<span class="kn">from</span> <span class="nn">cdopt.manifold_torch</span> <span class="kn">import</span> <span class="n">stiefel_torch</span>
<span class="kn">from</span> <span class="nn">cdopt.core.problem</span> <span class="kn">import</span> <span class="n">Problem</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="c1"># Set parameters</span>
<span class="n">m</span> <span class="o">=</span> <span class="mi">200</span>  <span class="c1"># column size</span>
<span class="n">s</span> <span class="o">=</span> <span class="mi">8</span>    <span class="c1"># row size</span>
<span class="n">beta</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># penalty parameter</span>
<span class="n">local_device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>  <span class="c1"># the device to perform the computation</span>
<span class="n">local_dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float64</span>  <span class="c1"># the data type of the pytorch tensor</span>

<span class="c1"># Define object function</span>
<span class="n">H</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="n">m</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span> <span class="o">=</span><span class="n">local_device</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">local_dtype</span><span class="p">)</span>
<span class="n">H</span> <span class="o">=</span> <span class="n">H</span><span class="o">+</span><span class="n">H</span><span class="o">.</span><span class="n">T</span> 

<span class="k">def</span> <span class="nf">obj_fun</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="k">return</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span> <span class="n">X</span> <span class="o">*</span> <span class="p">(</span><span class="n">H</span><span class="nd">@X</span><span class="p">))</span> 


<span class="c1"># Set optimization problems and retrieve constraint dissolving functions.</span>
<span class="n">M</span> <span class="o">=</span> <span class="n">stiefel_torch</span><span class="p">((</span><span class="n">m</span><span class="p">,</span><span class="n">s</span><span class="p">),</span> <span class="n">device</span> <span class="o">=</span><span class="n">local_device</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">local_dtype</span> <span class="p">)</span>
<span class="n">problem_test</span> <span class="o">=</span> <span class="n">Problem</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">obj_fun</span><span class="p">,</span> <span class="n">beta</span> <span class="o">=</span> <span class="n">beta</span><span class="p">)</span>
</pre></div>
</div>
<p>On the one hand, we can use the interface provided by <code class="docutils literal notranslate"><span class="pre">cdopt.core.Problem</span></code> class to retrieve the constraint dissolving function that adopts <code class="docutils literal notranslate"><span class="pre">scipy.optimize</span></code> package.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">cdf_fun_np</span> <span class="o">=</span> <span class="n">problem_test</span><span class="o">.</span><span class="n">cdf_fun_vec_np</span>   
<span class="n">cdf_grad_np</span> <span class="o">=</span> <span class="n">problem_test</span><span class="o">.</span><span class="n">cdf_grad_vec_np</span>
<span class="n">cdf_hvp_np</span> <span class="o">=</span> <span class="n">problem_test</span><span class="o">.</span><span class="n">cdf_hvp_vec_np</span>

<span class="c1"># Implement L-BFGS solver from scipy.optimize</span>
<span class="n">Xinit</span> <span class="o">=</span> <span class="n">M</span><span class="o">.</span><span class="n">tensor2array</span><span class="p">(</span><span class="n">M</span><span class="o">.</span><span class="n">Init_point</span><span class="p">())</span>
<span class="n">out_msg</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">optimize</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">cdf_fun_np</span><span class="p">,</span> <span class="n">Xinit</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;L-BFGS-B&#39;</span><span class="p">,</span><span class="n">jac</span> <span class="o">=</span> <span class="n">cdf_grad_np</span><span class="p">)</span>

<span class="c1"># Implement L-BFGS solver from scipy.optimize</span>
<span class="n">Xinit</span> <span class="o">=</span> <span class="n">M</span><span class="o">.</span><span class="n">tensor2array</span><span class="p">(</span><span class="n">M</span><span class="o">.</span><span class="n">Init_point</span><span class="p">())</span>
<span class="n">t_start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">out_msg</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">optimize</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">cdf_fun_np</span><span class="p">,</span> <span class="n">Xinit</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;L-BFGS-B&#39;</span><span class="p">,</span><span class="n">jac</span> <span class="o">=</span> <span class="n">cdf_grad_np</span><span class="p">)</span>
<span class="n">t_end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t_start</span>

<span class="c1"># Statistics</span>
<span class="n">feas</span> <span class="o">=</span> <span class="n">M</span><span class="o">.</span><span class="n">Feas_eval</span><span class="p">(</span><span class="n">M</span><span class="o">.</span><span class="n">v2m</span><span class="p">(</span><span class="n">M</span><span class="o">.</span><span class="n">array2tensor</span><span class="p">(</span><span class="n">out_msg</span><span class="o">.</span><span class="n">x</span><span class="p">)))</span>   <span class="c1"># Feasibility</span>
<span class="n">stationarity</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">out_msg</span><span class="p">[</span><span class="s1">&#39;jac&#39;</span><span class="p">],</span><span class="mi">2</span><span class="p">)</span>   <span class="c1"># stationarity</span>
<span class="n">result_lbfgs</span> <span class="o">=</span> <span class="p">[</span><span class="n">out_msg</span><span class="p">[</span><span class="s1">&#39;fun&#39;</span><span class="p">],</span> <span class="n">out_msg</span><span class="p">[</span><span class="s1">&#39;nit&#39;</span><span class="p">],</span> <span class="n">out_msg</span><span class="p">[</span><span class="s1">&#39;nfev&#39;</span><span class="p">],</span><span class="n">stationarity</span><span class="p">,</span><span class="n">feas</span><span class="p">,</span> <span class="n">t_end</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&amp; L-BFGS &amp; </span><span class="si">{:.2e}</span><span class="s1"> &amp; </span><span class="si">{:}</span><span class="s1"> &amp; </span><span class="si">{:}</span><span class="s1"> &amp; </span><span class="si">{:.2e}</span><span class="s1"> &amp; </span><span class="si">{:.2e}</span><span class="s1"> &amp; </span><span class="si">{:.2f}</span><span class="s1"> </span><span class="se">\\\\</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">result_lbfgs</span><span class="p">))</span>
</pre></div>
</div>
<p>On the other hand, we can also employ the solvers from <code class="docutils literal notranslate"><span class="pre">torch.optim</span></code> and <code class="docutils literal notranslate"><span class="pre">torch_optimizer</span></code> packages to minimize the constraint dissolving function.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">cdf_fun</span> <span class="o">=</span> <span class="n">problem_test</span><span class="o">.</span><span class="n">cdf_fun</span>
<span class="k">class</span> <span class="nc">Model</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xinit</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">M</span><span class="o">.</span><span class="n">Init_point</span><span class="p">(</span><span class="n">Xinit</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cdf_fun</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">M</span><span class="o">.</span><span class="n">Init_point</span><span class="p">())</span>
<span class="n">optim</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">train_epoch</span><span class="p">(</span><span class="n">epoch</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">closure</span><span class="p">():</span>
        <span class="n">optim</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">model</span><span class="p">()</span>
        <span class="p">(</span><span class="n">loss</span><span class="p">)</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">loss</span>
    <span class="n">optim</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">closure</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="k">for</span> <span class="n">jj</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2000</span><span class="p">)):</span>
    <span class="n">train_epoch</span><span class="p">(</span><span class="n">jj</span><span class="p">)</span>
    
<span class="n">X_fin</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">X</span>
<span class="n">M</span><span class="o">.</span><span class="n">Feas_eval</span><span class="p">(</span><span class="n">X_fin</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./md_files\tutorials"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="../tutorial.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Tutorials</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="define_manifolds.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Define your own manifold</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Nachuan Xiao, Xiaoyin Hu, Xin Liu, Kim-Chuan Toh<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>