
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Quickstart &#8212; Constraint Dissolving Approaches for Riemannian Optimization</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'md_files/tutorials/quick_start';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Training neural networks with manifold constraints" href="build_networks.html" />
    <link rel="prev" title="Tutorials" href="../tutorial.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
  
    <p class="title logo__title">Constraint Dissolving Approaches for Riemannian Optimization</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Welcome to CDOpt
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../tutorial.html">Tutorials</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Quickstart</a></li>
<li class="toctree-l2"><a class="reference internal" href="build_networks.html">Training neural networks with manifold constraints</a></li>
<li class="toctree-l2"><a class="reference internal" href="define_manifolds.html">Define your own manifold</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../examples.html">Examples</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../examples/example_scipy.html">Optimization via SciPy</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../examples/dictionary_learning.html">Dictionary Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../examples/dictionary_learning_jax.html">Dictionary Learning Accelerated by JIT</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../examples/nonlinear_eigenvalue.html">Discretized 1D Kohn-Sham Equation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../examples/nearest_correlation_estimation.html">Low-Rank Nearest Correlation Estimation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../examples/bose_einstein_condensates.html">Boseâ€“Einstein Condensates</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../examples/symplectic_eigenvalue.html">Symplectic Eigenvalue Problem</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../examples/example_torch.html">Training Neural Networks with Manifold Constraints via PyTorch</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../examples/LeNet_orth.html">Training LeNet with Constrained Convolution Kernels</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../examples/rnn_single_layer.html">Training Single-Layer RNN with Constrained Weights</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../examples/rnn_multi_layer.html">Training Multi-Layer RNN with Constrained Weights</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../examples/rnn_lstm.html">Training LSTM with Constrained Weights</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../examples/sine_sequence.html">Time Sequence Prediction with Orthogonality Constrained LSTM</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../examples/distributed_rnn_basic.html">Distributed Training for RNN with Constrained Weights</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../examples/distributed_linear_basic.html">Distributed Training for A Simple Network by Distributed RPC Framework</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../examples/example_jax.html">Training Neural Networks with Manifold Constraints via JAX and FLAX</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../examples/LeNet_orth_jax.html">Training LeNet with Constrained Convolution Kernels by JAX and FLAX</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../api_reference.html">API Reference</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../apis/cdopt_core.html">cdopt.core</a></li>
<li class="toctree-l2"><a class="reference internal" href="../apis/cdopt_manifold.html">cdopt.manifold</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../apis/cdopt_manifold_np.html">cdopt.manifold_np</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../apis/manifold_np/basic_manifold_np.html">basic_manifold_np</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/manifold_np/euclidean_np.html">euclidean_np</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/manifold_np/sphere_np.html">sphere_np</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/manifold_np/oblique_np.html">oblique_np</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/manifold_np/stiefel_np.html">stiefel_np</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/manifold_np/grassmann_np.html">grassmann_np</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/manifold_np/generalized_stiefel_np.html">generalized_stiefel_np</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/manifold_np/hyperbolic_np.html">hyperbolic_np</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/manifold_np/symp_stiefel_np.html">symp_stiefel_np</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../apis/cdopt_manifold_torch.html">cdopt.manifold_torch</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../apis/manifold_torch/basic_manifold_torch.html">basic_manifold_torch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/manifold_torch/euclidean_torch.html">euclidean_torch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/manifold_torch/sphere_torch.html">sphere_torch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/manifold_torch/oblique_torch.html">oblique_torch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/manifold_torch/stiefel_torch.html">stiefel_torch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/manifold_torch/grassmann_torch.html">grassmann_torch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/manifold_torch/generalized_stiefel_torch.html">generalized_stiefel_torch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/manifold_torch/hyperbolic_torch.html">hyperbolic_torch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/manifold_torch/symp_stiefel_torch.html">symp_stiefel_torch</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../apis/cdopt_nn.html">cdopt.nn</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../apis/nn/cdopt_nn_utils.html">cdopt.nn.utils</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../apis/nn/utils/stateless.html">cdopt.nn.utils.stateless</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apis/nn/utils/modified_apply.html">cdopt.nn.utils.modified_apply</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apis/nn/utils/set_constraints.html">cdopt.nn.utils.set_constraints</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../apis/nn/cdopt_nn_module.html">cdopt.nn.module</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../apis/nn/module/linear_cdopt.html">Linear_cdopt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apis/nn/module/bilinear_cdopt.html">Bilinear</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apis/nn/module/conv1d_cdopt.html">Conv1d_cdopt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apis/nn/module/conv2d_cdopt.html">Conv2d_cdopt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apis/nn/module/conv3d_cdopt.html">Conv3d_cdopt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apis/nn/module/rnnbase_cdopt.html">RNNBase_cdopt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apis/nn/module/rnn_cdopt.html">RNN_cdopt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apis/nn/module/lstm_cdopt.html">LSTM_cdopt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apis/nn/module/gru_cdopt.html">GRU_cdopt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apis/nn/module/rnncell_cdopt.html">RNNCell_cdopt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apis/nn/module/lstmcell_cdopt.html">LSTMCell_cdopt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apis/nn/module/grucell_cdopt.html">GRUCell_cdopt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apis/nn/module/utils.html">cdopt.nn.module.utils</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../apis/cdopt_linen.html">cdopt.linen</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../apis/linen/Linear_cdopt.html">linen.linear</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../about.html">About CDOpt</a></li>
<li class="toctree-l1"><a class="reference internal" href="../update_log.html">Update log</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/cdopt/cdopt.github.io" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/cdopt/cdopt.github.io/issues/new?title=Issue%20on%20page%20%2Fmd_files/tutorials/quick_start.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/md_files/tutorials/quick_start.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Quickstart</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-simple-example">A simple example</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#manifolds">Manifolds</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#solvers">Solvers</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#automatic-differentiation-backbones">Automatic differentiation backbones</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cuda-support">CUDA support</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="quickstart">
<h1>Quickstart<a class="headerlink" href="#quickstart" title="Link to this heading">#</a></h1>
<section id="a-simple-example">
<h2>A simple example<a class="headerlink" href="#a-simple-example" title="Link to this heading">#</a></h2>
<p>We begin with a simple optimization problem with orthogonality constraints,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
		\min_{X \in \mathbb{R}^{m\times s}}\quad &amp;f(X) = -\frac{1}{2}\mathrm{tr}(X^\top HX)\\
		\text{s.t.} \quad &amp; X^\top X = I_s,
	\end{aligned}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(H \in \mathbb{R}^{m\times m}\)</span> is a symmetric matrix, and the gradient of <span class="math notranslate nohighlight">\(f\)</span> can be expressed as</p>
<div class="math notranslate nohighlight">
\[
\nabla f(X) = -HX.
\]</div>
<p>The constraints on the matrix <span class="math notranslate nohighlight">\(X\)</span> require that <span class="math notranslate nohighlight">\(X\)</span> should be an orthogonal matrix, i.e., <span class="math notranslate nohighlight">\(X\)</span> lies on the Stiefel manifold,</p>
<div class="math notranslate nohighlight">
\[
\mathcal{S}_{m,s} = \{X \in \mathbb{R}^{m\times s}: X^\top X = I_s  \}.
\]</div>
<p>The following is a minimal working example of how to solve the above problem using CDOpt for a random symmetric matrix. As indicated in the introduction above, we follow four simple steps: we instantiate the manifold, create the cost function (using PyTorch in this case), define a problem instance which we pass the manifold and the cost function, and run the minimization problem using one of the existing unconstrained optimization solvers.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import basic functions</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy</span> <span class="k">as</span> <span class="nn">sp</span>
<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">fmin_bfgs</span><span class="p">,</span> <span class="n">fmin_cg</span><span class="p">,</span> <span class="n">fmin_l_bfgs_b</span><span class="p">,</span> <span class="n">fmin_ncg</span>
<span class="kn">import</span> <span class="nn">torch</span> 
<span class="kn">import</span> <span class="nn">cdopt</span>
<span class="kn">from</span> <span class="nn">cdopt.manifold_torch</span> <span class="kn">import</span> <span class="n">stiefel_torch</span>
<span class="kn">from</span> <span class="nn">cdopt.core.problem</span> <span class="kn">import</span> <span class="n">problem</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="c1"># Set parameters</span>
<span class="n">m</span> <span class="o">=</span> <span class="mi">200</span>  <span class="c1"># column size</span>
<span class="n">s</span> <span class="o">=</span> <span class="mi">8</span>    <span class="c1"># row size</span>
<span class="n">beta</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># penalty parameter</span>
<span class="n">local_device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>  <span class="c1"># the device to perform the computation</span>
<span class="n">local_dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float64</span>  <span class="c1"># the data type of the pytorch tensor</span>

<span class="c1"># Define object function</span>
<span class="n">H</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="n">m</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span> <span class="o">=</span><span class="n">local_device</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">local_dtype</span><span class="p">)</span>
<span class="n">H</span> <span class="o">=</span> <span class="n">H</span><span class="o">+</span><span class="n">H</span><span class="o">.</span><span class="n">T</span> 

<span class="k">def</span> <span class="nf">obj_fun</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="k">return</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span> <span class="n">X</span> <span class="o">*</span> <span class="p">(</span><span class="n">H</span><span class="nd">@X</span><span class="p">))</span> 


<span class="c1"># Set optimization problems and retrieve constraint dissolving functions.</span>
<span class="n">M</span> <span class="o">=</span> <span class="n">stiefel_torch</span><span class="p">((</span><span class="n">m</span><span class="p">,</span><span class="n">s</span><span class="p">),</span> <span class="n">device</span> <span class="o">=</span><span class="n">local_device</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">local_dtype</span> <span class="p">)</span>
<span class="n">problem_test</span> <span class="o">=</span> <span class="n">problem</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">obj_fun</span><span class="p">,</span> <span class="n">beta</span> <span class="o">=</span> <span class="n">beta</span><span class="p">)</span>

<span class="n">cdf_fun_np</span> <span class="o">=</span> <span class="n">problem_test</span><span class="o">.</span><span class="n">cdf_fun_vec_np</span>
<span class="n">cdf_grad_np</span> <span class="o">=</span> <span class="n">problem_test</span><span class="o">.</span><span class="n">cdf_grad_vec_np</span>
<span class="n">cdf_hvp_np</span> <span class="o">=</span> <span class="n">problem_test</span><span class="o">.</span><span class="n">cdf_hvp_vec_np</span>

<span class="c1"># Implement L-BFGS solver from scipy.optimize</span>
<span class="n">Xinit</span> <span class="o">=</span> <span class="n">problem_test</span><span class="o">.</span><span class="n">Xinit_vec_np</span>
<span class="n">t_start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">out_msg</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">optimize</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">cdf_fun_np</span><span class="p">,</span> <span class="n">Xinit</span><span class="p">,</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;L-BFGS-B&#39;</span><span class="p">,</span><span class="n">jac</span> <span class="o">=</span> <span class="n">cdf_grad_np</span><span class="p">)</span>
<span class="n">t_run</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t_start</span>

<span class="c1"># Statistics</span>
<span class="n">feas</span> <span class="o">=</span> <span class="n">M</span><span class="o">.</span><span class="n">Feas_eval</span><span class="p">(</span><span class="n">M</span><span class="o">.</span><span class="n">v2m</span><span class="p">(</span><span class="n">M</span><span class="o">.</span><span class="n">array2tensor</span><span class="p">(</span><span class="n">out_msg</span><span class="o">.</span><span class="n">x</span><span class="p">)))</span>   <span class="c1"># Feasibility</span>
<span class="n">stationarity</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">out_msg</span><span class="p">[</span><span class="s1">&#39;jac&#39;</span><span class="p">],</span><span class="mi">2</span><span class="p">)</span>   <span class="c1"># stationarity</span>
<span class="n">result_lbfgs</span> <span class="o">=</span> <span class="p">[</span><span class="n">out_msg</span><span class="p">[</span><span class="s1">&#39;fun&#39;</span><span class="p">],</span> <span class="n">out_msg</span><span class="p">[</span><span class="s1">&#39;nit&#39;</span><span class="p">],</span> <span class="n">out_msg</span><span class="p">[</span><span class="s1">&#39;nfev&#39;</span><span class="p">],</span><span class="n">stationarity</span><span class="p">,</span><span class="n">feas</span><span class="p">,</span> <span class="n">t_run</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&amp; L-BFGS &amp; </span><span class="si">{:.2e}</span><span class="s1"> &amp; </span><span class="si">{:}</span><span class="s1"> &amp; </span><span class="si">{:}</span><span class="s1"> &amp; </span><span class="si">{:.2e}</span><span class="s1"> &amp; </span><span class="si">{:.2e}</span><span class="s1"> &amp; </span><span class="si">{:.2f}</span><span class="s1"> </span><span class="se">\\\\</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">result_lbfgs</span><span class="p">))</span>
</pre></div>
</div>
<p>Now let us take a deeper look at the code step by step. First, we imports necessary packages and set the parameters for the optimization problem.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import basic functions</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy</span> <span class="k">as</span> <span class="nn">sp</span>
<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">fmin_bfgs</span><span class="p">,</span> <span class="n">fmin_cg</span><span class="p">,</span> <span class="n">fmin_l_bfgs_b</span><span class="p">,</span> <span class="n">fmin_ncg</span>
<span class="kn">import</span> <span class="nn">torch</span> 
<span class="kn">import</span> <span class="nn">cdopt</span>
<span class="kn">from</span> <span class="nn">cdopt.manifold_torch</span> <span class="kn">import</span> <span class="n">stiefel_torch</span>
<span class="kn">from</span> <span class="nn">cdopt.core.problem</span> <span class="kn">import</span> <span class="n">problem</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="c1"># Set parameters</span>
<span class="n">m</span> <span class="o">=</span> <span class="mi">200</span>  <span class="c1"># column size</span>
<span class="n">s</span> <span class="o">=</span> <span class="mi">8</span>    <span class="c1"># row size</span>
<span class="n">beta</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># penalty parameter</span>
<span class="n">local_device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>  <span class="c1"># the device to perform the computation</span>
<span class="n">local_dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float64</span>  <span class="c1"># the data type of the pytorch tensor</span>
</pre></div>
</div>
<p>Then we describe the objective function, where the variables are PyTorch tensors. The cost function can be compatible to the automatic differentiation (AD) packages in PyTorch. Otherwise, we need to manually provide the gradient and Hessian-vector produce of the objective function.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define object function</span>
<span class="n">H</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="n">m</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span> <span class="o">=</span><span class="n">local_device</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">local_dtype</span><span class="p">)</span>
<span class="n">H</span> <span class="o">=</span> <span class="n">H</span> <span class="o">+</span> <span class="n">H</span><span class="o">.</span><span class="n">T</span> 

<span class="k">def</span> <span class="nf">obj_fun</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="k">return</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span> <span class="n">X</span> <span class="o">*</span> <span class="p">(</span><span class="n">H</span><span class="nd">@X</span><span class="p">))</span>  
</pre></div>
</div>
<p>Then we call <code class="docutils literal notranslate"><span class="pre">stiefel_torch</span></code> to generate a structure that describes the Stiefel manifold <span class="math notranslate nohighlight">\(\mathcal{S}_{n,p}\)</span>. This manifold corresponds to the constraint appearing in our optimization problem. For other constraints, take a look at the <a class="reference internal" href="#manifolds"><span class="xref myst">various supported manifolds</span></a> for details. The second instruction creates a structure named <code class="docutils literal notranslate"><span class="pre">problem_test</span></code>. Here the gradients and hessians of the objective function are not necessary, as they can be computed by the AD packages provided by PyTorch.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set optimization problems and retrieve constraint dissolving functions.</span>
<span class="n">M</span> <span class="o">=</span> <span class="n">stiefel_torch</span><span class="p">((</span><span class="n">m</span><span class="p">,</span><span class="n">s</span><span class="p">),</span> <span class="n">device</span> <span class="o">=</span><span class="n">local_device</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">local_dtype</span> <span class="p">)</span>
<span class="n">problem_test</span> <span class="o">=</span> <span class="n">problem</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">obj_fun</span><span class="p">,</span> <span class="n">beta</span> <span class="o">=</span> <span class="n">beta</span><span class="p">)</span>
</pre></div>
</div>
<p>After describe the optimization problem, we can directly retrieve the function value, gradients, Hessian-vector product of the corresponding constraint dissolving function.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get the objective function, gradient, hessian-vector product </span>
<span class="c1"># of the corresponding constraint dissolving function</span>
<span class="n">cdf_fun_np</span> <span class="o">=</span> <span class="n">problem_test</span><span class="o">.</span><span class="n">cdf_fun_vec_np</span>   
<span class="n">cdf_grad_np</span> <span class="o">=</span> <span class="n">problem_test</span><span class="o">.</span><span class="n">cdf_grad_vec_np</span>
<span class="n">cdf_hvp_np</span> <span class="o">=</span> <span class="n">problem_test</span><span class="o">.</span><span class="n">cdf_hvp_vec_np</span>
</pre></div>
</div>
<p>Finally, we call the L-BFGS solver from <code class="docutils literal notranslate"><span class="pre">scipy.optimize</span></code> package to minimize the constraint dissolving function over <span class="math notranslate nohighlight">\(\mathbb{R}^{n\times p}\)</span>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Implement L-BFGS solver from scipy.optimize</span>
<span class="n">Xinit</span> <span class="o">=</span> <span class="n">problem_test</span><span class="o">.</span><span class="n">Xinit_vec_np</span>
<span class="n">t_start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">out_msg</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">optimize</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">cdf_fun_np</span><span class="p">,</span> <span class="n">Xinit</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;L-BFGS-B&#39;</span><span class="p">,</span><span class="n">jac</span> <span class="o">=</span> <span class="n">cdf_grad_np</span><span class="p">)</span>
<span class="n">t_run</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t_start</span>


<span class="c1"># Statistics</span>
<span class="n">X_tensor</span> <span class="o">=</span> <span class="n">M</span><span class="o">.</span><span class="n">array2tensor</span><span class="p">(</span><span class="n">out_msg</span><span class="o">.</span><span class="n">x</span><span class="p">)</span>   <span class="c1"># Transfer the numpy 1D array to tensor</span>
<span class="n">X_var</span> <span class="o">=</span> <span class="n">M</span><span class="o">.</span><span class="n">v2m</span><span class="p">(</span><span class="n">X_tensor</span><span class="p">)</span>   <span class="c1"># Transfer the 1D tensor to the tensor with shape M.var_shape.</span>
<span class="n">feas</span> <span class="o">=</span> <span class="n">M</span><span class="o">.</span><span class="n">Feas_eval</span><span class="p">(</span><span class="n">X_var</span><span class="p">)</span>   <span class="c1"># Evaluate the feasibility</span>
<span class="n">stationarity</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">out_msg</span><span class="p">[</span><span class="s1">&#39;jac&#39;</span><span class="p">],</span><span class="mi">2</span><span class="p">)</span>   <span class="c1"># stationarity</span>
<span class="n">result_lbfgs</span> <span class="o">=</span> <span class="p">[</span><span class="n">out_msg</span><span class="p">[</span><span class="s1">&#39;fun&#39;</span><span class="p">],</span> <span class="n">out_msg</span><span class="p">[</span><span class="s1">&#39;nit&#39;</span><span class="p">],</span> <span class="n">out_msg</span><span class="p">[</span><span class="s1">&#39;nfev&#39;</span><span class="p">],</span><span class="n">stationarity</span><span class="p">,</span><span class="n">feas</span><span class="p">,</span> <span class="n">t_run</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&amp; L-BFGS &amp; </span><span class="si">{:.2e}</span><span class="s1"> &amp; </span><span class="si">{:}</span><span class="s1"> &amp; </span><span class="si">{:}</span><span class="s1"> &amp; </span><span class="si">{:.2e}</span><span class="s1"> &amp; </span><span class="si">{:.2e}</span><span class="s1"> &amp; </span><span class="si">{:.2f}</span><span class="s1"> </span><span class="se">\\\\</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">result_lbfgs</span><span class="p">))</span>
</pre></div>
</div>
</section>
<section id="manifolds">
<h2>Manifolds<a class="headerlink" href="#manifolds" title="Link to this heading">#</a></h2>
<p>For several well-known manifolds, we provide build-in expressions for <span class="math notranslate nohighlight">\(\mathcal{A}\)</span> in the following table. We strongly suggest you to use the pre-defined manifold class if it is included in the following table.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Expression of <span class="math notranslate nohighlight">\(c\)</span></p></th>
<th class="head"><p>Pre-defined structure by Numpy</p></th>
<th class="head"><p>Pre-defined structure by PyTorch</p></th>
<th class="head"><p>Pre-defined structure by JAX</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Euclidean space</p></td>
<td><p>No constraint</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">euclidean_np</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">euclidean_torch</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">euclidean_jax</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>Sphere</p></td>
<td><p><span class="math notranslate nohighlight">\(\left\{ x \in \mathbb{R}^{n}: x^\top x = 1 \right\}\)</span></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sphere_np</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sphere_torch</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sphere_jax</span></code></p></td>
</tr>
<tr class="row-even"><td><p>Oblique manifold</p></td>
<td><p><span class="math notranslate nohighlight">\(\left\{ X \in \mathbb{R}^{m\times s}: \mathrm{Diag} (X  X^\top) = I_m \right\}\)</span></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">obluqie_np</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">obluqie_torch</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">obluqie_jax</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>Stiefel manifold</p></td>
<td><p><span class="math notranslate nohighlight">\(\left\{ X \in \mathbb{R}^{m\times s}: X ^\top X = I_s \right\}\)</span></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">stiefel_np</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">stiefel_torch</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">stiefel_jax</span></code></p></td>
</tr>
<tr class="row-even"><td><p>Grassmann manifold</p></td>
<td><p><span class="math notranslate nohighlight">\(\left\{ \mathrm{range}(X): X \in \mathbb{R}^{m\times s}, X ^\top X = I_s \right\}\)</span></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">stiefel_np</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">stiefel_torch</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">stiefel_jax</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>Generalized Stiefel manifold</p></td>
<td><p><span class="math notranslate nohighlight">\(\left\{ X \in \mathbb{R}^{m\times s}: X ^\top B X = I_s \right\}\)</span>, <span class="math notranslate nohighlight">\(B\)</span> is positive definite</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">generalized_stiefel_np</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">generalized_stiefel_torch</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">generalized_stiefel_jax</span></code></p></td>
</tr>
<tr class="row-even"><td><p>Generalized Grassmann manifold</p></td>
<td><p><span class="math notranslate nohighlight">\(\left\{ \mathrm{range}(X): X \in \mathbb{R}^{m\times s}, X ^\top B X = I_s \right\}\)</span>, <span class="math notranslate nohighlight">\(B\)</span> is positive definite</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">generalized_stiefel_np</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">generalized_stiefel_torch</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">generalized_stiefel_jax</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>Hyperbolic manifold</p></td>
<td><p><span class="math notranslate nohighlight">\(\left\{ X \in \mathbb{R}^{m\times s}: X ^\top B X = I_s \right\}\)</span>, <span class="math notranslate nohighlight">\(\lambda_{\min}(B)&lt; 0 &lt; \lambda_{\max}(B)\)</span></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">hyperbolic_np</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">hyperbolic_torch</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">hyperbolic_jax</span></code></p></td>
</tr>
<tr class="row-even"><td><p>Symplectic Stiefel manifold</p></td>
<td><p><span class="math notranslate nohighlight">\(\left\{ X \in \mathbb{R}^{2m\times 2s}: X ^\top Q_m X = Q_s \right\}\)</span>, <span class="math notranslate nohighlight">\(Q_m := \left[ \begin{smallmatrix}	{\bf 0}_{m\times m} &amp; I_m\\			 -I_m &amp; {\bf 0}_{m\times m}			\end{smallmatrix}\right]\)</span></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">symp_stiefel_np</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">symp_stiefel_torch</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">symp_stiefel_jax</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>Complex sphere</p></td>
<td><p><span class="math notranslate nohighlight">\(\{x \in \mathbb{C}^n : x^H x = 1  \}\)</span></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">complex_shpere_np</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">complex_shpere_torch</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">complex_shpere_jax</span></code></p></td>
</tr>
<tr class="row-even"><td><p>Complex oblique manifold</p></td>
<td><p><span class="math notranslate nohighlight">\(\left\{ X \in \mathbb{C}^{m\times s}: \mathrm{Diag} (X  X^H) = I_m \right\}\)</span></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">complex_oblique_np</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">complex_oblique_torch</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">complex_oblique_jax</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>Complex Stiefel manifold</p></td>
<td><p><span class="math notranslate nohighlight">\(\left\{ X \in \mathbb{C}^{m\times s}: X ^H X = I_s \right\}\)</span></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">complex_stiefel_np</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">complex_stiefel_torch</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">complex_stiefel_jax</span></code></p></td>
</tr>
<tr class="row-even"><td><p>â€¦</p></td>
<td><p>â€¦</p></td>
<td><p>â€¦</p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="solvers">
<h2>Solvers<a class="headerlink" href="#solvers" title="Link to this heading">#</a></h2>
<p>In CDOpt, the Riemannian optimization problems are transferred into the unconstrained minimization of the constraint dissolving functions, which can be solved by various of existing solvers. As far as we tested, the solvers from <a class="reference external" href="https://www.pdfo.net/index.html">PDFO</a>, <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize">SciPy</a>, <a class="reference external" href="https://pytorch.org/docs/stable/optim.html">PyTorch</a>, <a class="reference external" href="https://github.com/jettify/pytorch-optimizer">pytorch-optimizer</a>, and <a class="reference external" href="https://github.com/google/jaxopt">jaxopt</a> packages can be directly applied to minimize the constraint dissolving functions yielded by CDOpt.</p>
</section>
<section id="automatic-differentiation-backbones">
<h2>Automatic differentiation backbones<a class="headerlink" href="#automatic-differentiation-backbones" title="Link to this heading">#</a></h2>
<p>CDOpt relies on the automatic differentiation (AD) packages to compute the derivatives of the objective function and build the constraint dissolving mapping. In CDOpt, we provide various of plug-in AD backbones in <code class="docutils literal notranslate"><span class="pre">cdopt.core</span></code> based on autograd and PyTorch packages. Moreover, one can easily build his own AD backbones based on other packages, including the <code class="docutils literal notranslate"><span class="pre">jax</span></code> and <code class="docutils literal notranslate"><span class="pre">tensorflow</span></code>.</p>
</section>
<section id="cuda-support">
<h2>CUDA support<a class="headerlink" href="#cuda-support" title="Link to this heading">#</a></h2>
<p>CDOpt utilizes the CUDA supports from the employed backbones. Both the computation of constraint dissolving mappings and the unconstrained minimization of the constraint dissolving functions can be accelerated by the CUDA support of the selected backbones.</p>
<p>For example, by setting the <code class="docutils literal notranslate"><span class="pre">local_device</span> <span class="pre">=</span> <span class="pre">torch.device('cuda')</span></code> in the following code blocks, all the computations for CDF are accelerated by CUDA.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import basic functions</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy</span> <span class="k">as</span> <span class="nn">sp</span>
<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">fmin_bfgs</span><span class="p">,</span> <span class="n">fmin_cg</span><span class="p">,</span> <span class="n">fmin_l_bfgs_b</span><span class="p">,</span> <span class="n">fmin_ncg</span>
<span class="kn">import</span> <span class="nn">torch</span> 
<span class="kn">import</span> <span class="nn">cdopt</span>
<span class="kn">from</span> <span class="nn">cdopt.manifold_torch</span> <span class="kn">import</span> <span class="n">stiefel_torch</span>
<span class="kn">from</span> <span class="nn">cdopt.core.problem</span> <span class="kn">import</span> <span class="n">problem</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="c1"># Set parameters</span>
<span class="n">m</span> <span class="o">=</span> <span class="mi">200</span>  <span class="c1"># column size</span>
<span class="n">s</span> <span class="o">=</span> <span class="mi">8</span>    <span class="c1"># row size</span>
<span class="n">beta</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># penalty parameter</span>
<span class="n">local_device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>  <span class="c1"># the device to perform the computation</span>
<span class="n">local_dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float64</span>  <span class="c1"># the data type of the pytorch tensor</span>

<span class="c1"># Define object function</span>
<span class="n">H</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="n">m</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span> <span class="o">=</span><span class="n">local_device</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">local_dtype</span><span class="p">)</span>
<span class="n">H</span> <span class="o">=</span> <span class="n">H</span><span class="o">+</span><span class="n">H</span><span class="o">.</span><span class="n">T</span> 

<span class="k">def</span> <span class="nf">obj_fun</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="k">return</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span> <span class="n">X</span> <span class="o">*</span> <span class="p">(</span><span class="n">H</span><span class="nd">@X</span><span class="p">))</span> 


<span class="c1"># Set optimization problems and retrieve constraint dissolving functions.</span>
<span class="n">M</span> <span class="o">=</span> <span class="n">stiefel_torch</span><span class="p">((</span><span class="n">m</span><span class="p">,</span><span class="n">s</span><span class="p">),</span> <span class="n">device</span> <span class="o">=</span><span class="n">local_device</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">local_dtype</span> <span class="p">)</span>
<span class="n">problem_test</span> <span class="o">=</span> <span class="n">problem</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">obj_fun</span><span class="p">,</span> <span class="n">beta</span> <span class="o">=</span> <span class="n">beta</span><span class="p">)</span>
</pre></div>
</div>
<p>On the one hand, we can use the interface provided by <code class="docutils literal notranslate"><span class="pre">cdopt.core.problem</span></code> class to retrieve the constraint dissolving function that adopts <code class="docutils literal notranslate"><span class="pre">scipy.optimize</span></code> package.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">cdf_fun_np</span> <span class="o">=</span> <span class="n">problem_test</span><span class="o">.</span><span class="n">cdf_fun_vec_np</span>   
<span class="n">cdf_grad_np</span> <span class="o">=</span> <span class="n">problem_test</span><span class="o">.</span><span class="n">cdf_grad_vec_np</span>
<span class="n">cdf_hvp_np</span> <span class="o">=</span> <span class="n">problem_test</span><span class="o">.</span><span class="n">cdf_hvp_vec_np</span>

<span class="c1"># Implement L-BFGS solver from scipy.optimize</span>
<span class="n">Xinit</span> <span class="o">=</span> <span class="n">M</span><span class="o">.</span><span class="n">tensor2array</span><span class="p">(</span><span class="n">M</span><span class="o">.</span><span class="n">Init_point</span><span class="p">())</span>
<span class="n">t_start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">out_msg</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">optimize</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">cdf_fun_np</span><span class="p">,</span> <span class="n">Xinit</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;L-BFGS-B&#39;</span><span class="p">,</span><span class="n">jac</span> <span class="o">=</span> <span class="n">cdf_grad_np</span><span class="p">)</span>
<span class="n">t_end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t_start</span>

<span class="c1"># Statistics</span>
<span class="n">feas</span> <span class="o">=</span> <span class="n">M</span><span class="o">.</span><span class="n">Feas_eval</span><span class="p">(</span><span class="n">M</span><span class="o">.</span><span class="n">v2m</span><span class="p">(</span><span class="n">M</span><span class="o">.</span><span class="n">array2tensor</span><span class="p">(</span><span class="n">out_msg</span><span class="o">.</span><span class="n">x</span><span class="p">)))</span>   <span class="c1"># Feasibility</span>
<span class="n">stationarity</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">out_msg</span><span class="p">[</span><span class="s1">&#39;jac&#39;</span><span class="p">],</span><span class="mi">2</span><span class="p">)</span>   <span class="c1"># stationarity</span>
<span class="n">result_lbfgs</span> <span class="o">=</span> <span class="p">[</span><span class="n">out_msg</span><span class="p">[</span><span class="s1">&#39;fun&#39;</span><span class="p">],</span> <span class="n">out_msg</span><span class="p">[</span><span class="s1">&#39;nit&#39;</span><span class="p">],</span> <span class="n">out_msg</span><span class="p">[</span><span class="s1">&#39;nfev&#39;</span><span class="p">],</span><span class="n">stationarity</span><span class="p">,</span><span class="n">feas</span><span class="p">,</span> <span class="n">t_end</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&amp; L-BFGS &amp; </span><span class="si">{:.2e}</span><span class="s1"> &amp; </span><span class="si">{:}</span><span class="s1"> &amp; </span><span class="si">{:}</span><span class="s1"> &amp; </span><span class="si">{:.2e}</span><span class="s1"> &amp; </span><span class="si">{:.2e}</span><span class="s1"> &amp; </span><span class="si">{:.2f}</span><span class="s1"> </span><span class="se">\\\\</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">result_lbfgs</span><span class="p">))</span>
</pre></div>
</div>
<p>On the other hand, we can also employ the solvers from <code class="docutils literal notranslate"><span class="pre">torch.optim</span></code> and <code class="docutils literal notranslate"><span class="pre">torch_optimizer</span></code> packages to minimize the constraint dissolving function.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">cdf_fun</span> <span class="o">=</span> <span class="n">problem_test</span><span class="o">.</span><span class="n">cdf_fun</span>
<span class="k">class</span> <span class="nc">Model</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xinit</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">M</span><span class="o">.</span><span class="n">Init_point</span><span class="p">(</span><span class="n">Xinit</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cdf_fun</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">M</span><span class="o">.</span><span class="n">Init_point</span><span class="p">())</span>
<span class="n">optim</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">train_epoch</span><span class="p">(</span><span class="n">epoch</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">closure</span><span class="p">():</span>
        <span class="n">optim</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">model</span><span class="p">()</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">loss</span>
    <span class="n">optim</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">closure</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="k">for</span> <span class="n">jj</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2000</span><span class="p">)):</span>
    <span class="n">train_epoch</span><span class="p">(</span><span class="n">jj</span><span class="p">)</span>
    
<span class="n">X_fin</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">X</span>
<span class="n">M</span><span class="o">.</span><span class="n">Feas_eval</span><span class="p">(</span><span class="n">X_fin</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./md_files\tutorials"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../tutorial.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Tutorials</p>
      </div>
    </a>
    <a class="right-next"
       href="build_networks.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Training neural networks with manifold constraints</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-simple-example">A simple example</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#manifolds">Manifolds</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#solvers">Solvers</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#automatic-differentiation-backbones">Automatic differentiation backbones</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cuda-support">CUDA support</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Nachuan Xiao, Xiaoyin Hu, Xin Liu, Kim-Chuan Toh
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      Â© Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>