
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Distributed Training for RNN with Constrained Weights &#8212; Constraint Dissolving Approaches for Riemannian Optimization</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=62ba249389abaaa9ffc34bf36a076bdc1d65ee18" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.14.0/dist/embed-amd.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Distributed Training for A Simple Network by Distributed RPC Framework" href="distributed_linear_basic.html" />
    <link rel="prev" title="Time Sequence Prediction with Orthogonality Constrained LSTM" href="sine_sequence.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Constraint Dissolving Approaches for Riemannian Optimization</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../md_files/intro.html">
                    Welcome to CDOpt
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../md_files/overview.html">
   Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../md_files/installation.html">
   Installation
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../md_files/tutorial.html">
   Tutorials
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../md_files/tutorials/quick_start.html">
     Quickstart
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../md_files/tutorials/define_manifolds.html">
     Define your own manifold
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../md_files/tutorials/build_networks.html">
     Training neural networks with constraints
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../md_files/examples.html">
   Examples
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="example_scipy.html">
     Optimization via SciPy
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
    <label for="toctree-checkbox-3">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="dictionary_learning.html">
       Dictionary Learning
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="dictionary_learning_jax.html">
       Dictionary Learning Accelerated by JIT
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="nonlinear_eigenvalue.html">
       Discretized 1D Kohn-Sham Equation
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="nearest_correlation_estimation.html">
       Low-Rank Nearest Correlation Estimation
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="bose_einstein_condensates.html">
       Boseâ€“Einstein Condensates
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="symplectic_eigenvalue.html">
       Symplectic Eigenvalue Problem
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 current active has-children">
    <a class="reference internal" href="example_torch.html">
     Training Neural Networks with Manifold Constraints via PyTorch
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
    <label for="toctree-checkbox-4">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="current">
     <li class="toctree-l3">
      <a class="reference internal" href="LeNet_orth.html">
       Training LeNet with Constrained Convolution Kernels
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="rnn_single_layer.html">
       Training Single-Layer RNN with Constrained Weights
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="rnn_multi_layer.html">
       Training Multi-Layer RNN with Constrained Weights
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="rnn_lstm.html">
       Training LSTM with Constrained Weights
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="sine_sequence.html">
       Time Sequence Prediction with Orthogonality Constrained LSTM
      </a>
     </li>
     <li class="toctree-l3 current active">
      <a class="current reference internal" href="#">
       Distributed Training for RNN with Constrained Weights
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="distributed_linear_basic.html">
       Distributed Training for A Simple Network by Distributed RPC Framework
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="example_jax.html">
     Training Neural Networks with Manifold Constraints via JAX and FLAX
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
    <label for="toctree-checkbox-5">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="LeNet_orth_jax.html">
       Training LeNet with Constrained Convolution Kernels by JAX and FLAX
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../md_files/api_reference.html">
   API Reference
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../md_files/apis/cdopt_core.html">
     cdopt.core
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../md_files/apis/cdopt_manifold.html">
     cdopt.manifold
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../md_files/apis/cdopt_manifold_np.html">
     cdopt.manifold_np
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
    <label for="toctree-checkbox-7">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../md_files/apis/manifold_np/basic_manifold_np.html">
       basic_manifold_np
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../md_files/apis/manifold_np/euclidean_np.html">
       euclidean_np
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../md_files/apis/manifold_np/sphere_np.html">
       sphere_np
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../md_files/apis/manifold_np/oblique_np.html">
       oblique_np
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../md_files/apis/manifold_np/stiefel_np.html">
       stiefel_np
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../md_files/apis/manifold_np/generalized_stiefel_np.html">
       generalized_stiefel_np
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../md_files/apis/manifold_np/hyperbolic_np.html">
       hyperbolic_np
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../md_files/apis/manifold_np/symp_stiefel_np.html">
       symp_stiefel_np
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../md_files/apis/cdopt_manifold_torch.html">
     cdopt.manifold_torch
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
    <label for="toctree-checkbox-8">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../md_files/apis/manifold_torch/basic_manifold_torch.html">
       basic_manifold_torch
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../md_files/apis/manifold_torch/euclidean_torch.html">
       euclidean_torch
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../md_files/apis/manifold_torch/sphere_torch.html">
       sphere_torch
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../md_files/apis/manifold_torch/oblique_torch.html">
       oblique_torch
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../md_files/apis/manifold_torch/stiefel_torch.html">
       stiefel_torch
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../md_files/apis/manifold_torch/generalized_stiefel_torch.html">
       generalized_stiefel_torch
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../md_files/apis/manifold_torch/hyperbolic_torch.html">
       hyperbolic_torch
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../md_files/apis/manifold_torch/symp_stiefel_torch.html">
       symp_stiefel_torch
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../md_files/apis/cdopt_nn.html">
     cdopt.nn
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
    <label for="toctree-checkbox-9">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../md_files/apis/nn/cdopt_nn_utils.html">
       cdopt.nn.utils
      </a>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../md_files/apis/nn/cdopt_nn_module.html">
       cdopt.nn.module
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
      <label for="toctree-checkbox-10">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../md_files/apis/nn/module/linear_cdopt.html">
         Linear_cdopt
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../md_files/apis/nn/module/bilinear_cdopt.html">
         Bilinear
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../md_files/apis/nn/module/conv1d_cdopt.html">
         Conv1d_cdopt
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../md_files/apis/nn/module/conv2d_cdopt.html">
         Conv2d_cdopt
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../md_files/apis/nn/module/conv3d_cdopt.html">
         Conv3d_cdopt
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../md_files/apis/nn/module/rnnbase_cdopt.html">
         RNNBase_cdopt
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../md_files/apis/nn/module/rnn_cdopt.html">
         RNN_cdopt
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../md_files/apis/nn/module/lstm_cdopt.html">
         LSTM_cdopt
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../md_files/apis/nn/module/gru_cdopt.html">
         GRU_cdopt
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../md_files/apis/nn/module/rnncell_cdopt.html">
         RNNCell_cdopt
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../md_files/apis/nn/module/lstmcell_cdopt.html">
         LSTMCell_cdopt
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../md_files/apis/nn/module/grucell_cdopt.html">
         GRUCell_cdopt
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../md_files/apis/cdopt_linen.html">
     cdopt.linen
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
    <label for="toctree-checkbox-11">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../md_files/apis/linen/Linear_cdopt.html">
       linen.linear
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../md_files/about.html">
   About CDOpt
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../md_files/update_log.html">
   Update log
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/xnchxy/constraint_dissolving_lib"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/xnchxy/constraint_dissolving_lib/issues/new?title=Issue%20on%20page%20%2Fexamples/distributed_rnn_basic.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/examples/distributed_rnn_basic.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Distributed Training for RNN with Constrained Weights</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="distributed-training-for-rnn-with-constrained-weights">
<h1>Distributed Training for RNN with Constrained Weights<a class="headerlink" href="#distributed-training-for-rnn-with-constrained-weights" title="Permalink to this headline">#</a></h1>
<p>This example shows how to build an RNN model using RPC where different components of the RNN model can be placed on different workers. To run the code, just save the following code as <code class="docutils literal notranslate"><span class="pre">main.py</span></code> and use the command <code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">main.py</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># import necessary modules</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.distributed.autograd</span> <span class="k">as</span> <span class="nn">dist_autograd</span>
<span class="kn">import</span> <span class="nn">torch.distributed.rpc</span> <span class="k">as</span> <span class="nn">rpc</span>
<span class="kn">import</span> <span class="nn">torch.multiprocessing</span> <span class="k">as</span> <span class="nn">mp</span>
<span class="kn">from</span> <span class="nn">torch.distributed.rpc</span> <span class="kn">import</span> <span class="n">RRef</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">from</span> <span class="nn">torch.distributed.optim</span> <span class="kn">import</span> <span class="n">DistributedOptimizer</span>

<span class="c1"># import cdopt components</span>
<span class="kn">import</span> <span class="nn">cdopt</span>
<span class="kn">from</span> <span class="nn">cdopt.manifold_torch</span> <span class="kn">import</span> <span class="n">stiefel_torch</span>


<span class="k">def</span> <span class="nf">_call_method</span><span class="p">(</span><span class="n">method</span><span class="p">,</span> <span class="n">rref</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    a helper function to call a method on the given RRef</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">method</span><span class="p">(</span><span class="n">rref</span><span class="o">.</span><span class="n">local_value</span><span class="p">(),</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_remote_method</span><span class="p">(</span><span class="n">method</span><span class="p">,</span> <span class="n">rref</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    a helper function to run method on the owner of rref and fetch back the</span>
<span class="sd">    result using RPC</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">rpc</span><span class="o">.</span><span class="n">rpc_sync</span><span class="p">(</span>
        <span class="n">rref</span><span class="o">.</span><span class="n">owner</span><span class="p">(),</span>
        <span class="n">_call_method</span><span class="p">,</span>
        <span class="n">args</span><span class="o">=</span><span class="p">[</span><span class="n">method</span><span class="p">,</span> <span class="n">rref</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">args</span><span class="p">),</span>
        <span class="n">kwargs</span><span class="o">=</span><span class="n">kwargs</span>
    <span class="p">)</span>


<span class="k">def</span> <span class="nf">_parameter_rrefs</span><span class="p">(</span><span class="n">module</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create one RRef for each parameter in the given local module, and return a</span>
<span class="sd">    list of RRefs.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">param_rrefs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
        <span class="n">param_rrefs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">RRef</span><span class="p">(</span><span class="n">param</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">param_rrefs</span>


<span class="k">class</span> <span class="nc">EmbeddingTable</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Encoding layers of the RNNModel</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ntoken</span><span class="p">,</span> <span class="n">ninp</span><span class="p">,</span> <span class="n">dropout</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">EmbeddingTable</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">drop</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">ntoken</span><span class="p">,</span> <span class="n">ninp</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
            <span class="nb">input</span> <span class="o">=</span> <span class="nb">input</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="nb">input</span><span class="p">))</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>


<span class="k">class</span> <span class="nc">Decoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Decoding layers of the RNNModel</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ntoken</span><span class="p">,</span> <span class="n">nhid</span><span class="p">,</span> <span class="n">dropout</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Decoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">drop</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">nhid</span><span class="p">,</span> <span class="n">ntoken</span><span class="p">)</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">zeros_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">output</span><span class="p">))</span>


<span class="k">class</span> <span class="nc">RNNModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A distributed RNN model which puts embedding table and decoder parameters on</span>
<span class="sd">    a remote parameter server, and locally holds parameters for the LSTM module.</span>
<span class="sd">    The structure of the RNN model is borrowed from the word language model</span>
<span class="sd">    example. See https://github.com/pytorch/examples/blob/main/word_language_model/model.py</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ps</span><span class="p">,</span> <span class="n">ntoken</span><span class="p">,</span> <span class="n">ninp</span><span class="p">,</span> <span class="n">nhid</span><span class="p">,</span> <span class="n">nlayers</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">RNNModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># setup embedding table remotely</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">emb_table_rref</span> <span class="o">=</span> <span class="n">rpc</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">ps</span><span class="p">,</span> <span class="n">EmbeddingTable</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">ntoken</span><span class="p">,</span> <span class="n">ninp</span><span class="p">,</span> <span class="n">dropout</span><span class="p">))</span>
        <span class="c1"># setup LSTM locally</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">cdopt</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LSTM_cdopt</span><span class="p">(</span><span class="n">ninp</span><span class="p">,</span> <span class="n">nhid</span><span class="p">,</span> <span class="n">nlayers</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">,</span> <span class="n">manifold_class</span> <span class="o">=</span> <span class="n">stiefel_torch</span><span class="p">)</span>
        <span class="c1"># setup decoder remotely</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder_rref</span> <span class="o">=</span> <span class="n">rpc</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">ps</span><span class="p">,</span> <span class="n">Decoder</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">ntoken</span><span class="p">,</span> <span class="n">nhid</span><span class="p">,</span> <span class="n">dropout</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hidden</span><span class="p">):</span>
        <span class="c1"># pass input to the remote embedding table and fetch emb tensor back</span>
        <span class="n">emb</span> <span class="o">=</span> <span class="n">_remote_method</span><span class="p">(</span><span class="n">EmbeddingTable</span><span class="o">.</span><span class="n">forward</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">emb_table_rref</span><span class="p">,</span> <span class="nb">input</span><span class="p">)</span>
        <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">emb</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
        <span class="c1"># pass output to the remote decoder and get the decoded output back</span>
        <span class="n">decoded</span> <span class="o">=</span> <span class="n">_remote_method</span><span class="p">(</span><span class="n">Decoder</span><span class="o">.</span><span class="n">forward</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_rref</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">decoded</span><span class="p">,</span> <span class="n">hidden</span>

    <span class="k">def</span> <span class="nf">parameter_rrefs</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">remote_params</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># get RRefs of embedding table</span>
        <span class="n">remote_params</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">_remote_method</span><span class="p">(</span><span class="n">_parameter_rrefs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">emb_table_rref</span><span class="p">))</span>
        <span class="c1"># create RRefs for local parameters</span>
        <span class="n">remote_params</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">_parameter_rrefs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">))</span>
        <span class="c1"># get RRefs of decoder</span>
        <span class="n">remote_params</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">_remote_method</span><span class="p">(</span><span class="n">_parameter_rrefs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_rref</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">remote_params</span>


<span class="k">def</span> <span class="nf">_run_trainer</span><span class="p">():</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The trainer creates a distributed RNNModel and a DistributedOptimizer. Then,</span>
<span class="sd">    it performs training using random input data.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">batch</span> <span class="o">=</span> <span class="mi">5</span>
    <span class="n">ntoken</span> <span class="o">=</span> <span class="mi">7</span>
    <span class="n">ninp</span> <span class="o">=</span> <span class="mi">2</span>

    <span class="n">nhid</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">nindices</span> <span class="o">=</span> <span class="mi">6</span>
    <span class="n">nlayers</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">hidden</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">nlayers</span><span class="p">,</span> <span class="n">nindices</span><span class="p">,</span> <span class="n">nhid</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">nlayers</span><span class="p">,</span> <span class="n">nindices</span><span class="p">,</span> <span class="n">nhid</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">RNNModel</span><span class="p">(</span><span class="s1">&#39;ps&#39;</span><span class="p">,</span> <span class="n">ntoken</span><span class="p">,</span> <span class="n">ninp</span><span class="p">,</span> <span class="n">nhid</span><span class="p">,</span> <span class="n">nlayers</span><span class="p">)</span>

    <span class="c1"># setup distributed optimizer</span>
    <span class="n">opt</span> <span class="o">=</span> <span class="n">DistributedOptimizer</span><span class="p">(</span>
        <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">,</span>
        <span class="n">model</span><span class="o">.</span><span class="n">parameter_rrefs</span><span class="p">(),</span>
        <span class="n">lr</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">get_next_batch</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">nindices</span><span class="p">)</span> <span class="o">%</span> <span class="n">ntoken</span>
            <span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">ntoken</span><span class="p">)</span> <span class="o">%</span> <span class="n">nindices</span>
            <span class="k">yield</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span>

    <span class="c1"># train for 10 iterations</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
        <span class="c1"># create distributed autograd context</span>
        <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">get_next_batch</span><span class="p">():</span>
            <span class="k">with</span> <span class="n">dist_autograd</span><span class="o">.</span><span class="n">context</span><span class="p">()</span> <span class="k">as</span> <span class="n">context_id</span><span class="p">:</span>
                <span class="n">hidden</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">detach_</span><span class="p">()</span>
                <span class="n">hidden</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">detach_</span><span class="p">()</span>
                <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
                <span class="c1"># run distributed backward pass</span>
                <span class="n">dist_autograd</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">context_id</span><span class="p">,</span> <span class="p">[</span><span class="n">loss</span><span class="p">])</span>
                <span class="c1"># run distributed optimizer</span>
                <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">context_id</span><span class="p">)</span>
                <span class="c1"># not necessary to zero grads as each iteration creates a different</span>
                <span class="c1"># distributed autograd context which hosts different grads</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training epoch </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">run_worker</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">world_size</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A wrapper function that initializes RPC, calls the function, and shuts down</span>
<span class="sd">    RPC.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;MASTER_ADDR&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;localhost&#39;</span>
    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;MASTER_PORT&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;29500&#39;</span>
    <span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">rpc</span><span class="o">.</span><span class="n">init_rpc</span><span class="p">(</span><span class="s2">&quot;trainer&quot;</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="n">rank</span><span class="p">,</span> <span class="n">world_size</span><span class="o">=</span><span class="n">world_size</span><span class="p">)</span>
        <span class="n">_run_trainer</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">rpc</span><span class="o">.</span><span class="n">init_rpc</span><span class="p">(</span><span class="s2">&quot;ps&quot;</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="n">rank</span><span class="p">,</span> <span class="n">world_size</span><span class="o">=</span><span class="n">world_size</span><span class="p">)</span>
        <span class="c1"># parameter server does nothing</span>
        <span class="k">pass</span>

    <span class="c1"># block until all rpcs finish</span>
    <span class="n">rpc</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">world_size</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">mp</span><span class="o">.</span><span class="n">spawn</span><span class="p">(</span><span class="n">run_worker</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">world_size</span><span class="p">,</span> <span class="p">),</span> <span class="n">nprocs</span><span class="o">=</span><span class="n">world_size</span><span class="p">,</span> <span class="n">join</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

</pre></div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./examples"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="sine_sequence.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Time Sequence Prediction with Orthogonality Constrained LSTM</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="distributed_linear_basic.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Distributed Training for A Simple Network by Distributed RPC Framework</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Nachuan Xiao, Xiaoyin Hu, Xin Liu, Kim-Chuan Toh<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>